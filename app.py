import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sentence_transformers import SentenceTransformer, util
from sklearn.feature_extraction.text import CountVectorizer
import torch
import re
import io

# =========================
# 0. é¡µé¢é…ç½®ä¸å®‰å…¨éªŒè¯
# =========================
st.set_page_config(
    page_title="æ™ºèƒ½è¯„è®ºæ ‡ç­¾æŒ–æ˜ç³»ç»Ÿ",
    page_icon="â›ï¸",
    layout="wide"
)

ACCESS_PASSWORD = "admin123" 

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state["password_input"] == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop() 

# =========================
# 1. æ‚¨çš„æ ‡å‡†æ ‡ç­¾åº“
# =========================
POS_LABELS = [
    "é¢æ–™èˆ’é€‚/æŸ”è½¯", "åšå·¥è´¨é‡å¥½", "ç¼“è§£ç–¼ç—›/åŒ»ç–—æ•ˆæœ", "ä¿æš–æ€§èƒ½å¥½", 
    "å°ºç åˆèº«/èˆ’é€‚è´´åˆ", "æä¾›å‹ç¼©æ„Ÿ/æ”¯æ’‘åŠ›", "å¢åŠ æŠ“æ¡åŠ›/é˜²æ»‘", 
    "å…³èŠ‚ç‚/æ‰³æœºæŒ‡è¾…åŠ©", "çµæ´»æ€§å¥½", "è€ç”¨æ€§å¼º", "è½»ç›ˆé€æ°”"
]

NEG_LABELS = [
    "æ— æ•ˆ/æ²¡æœ‰ä½œç”¨", "ç¼çº¿å¼€è£‚/ç ´æŸ", "æ”¶åˆ°äºŒæ‰‹/è„æ±¡", "é¢æ–™è´¨é‡å·®/å»‰ä»·", 
    "å°ºç å¤ªå°/å¤ªç´§", "å°ºç å¤ªå¤§/å¤ªæ¾", "æ¥ç¼å¤„ç£¨æ‰‹/ä¸é€‚", "ä¸è€ç”¨/ä¸€æ¬¡æ€§", 
    "è¿‡æ•/çš®ç–¹/å‘ç—’", "å¤ªæ»‘/æ²¡æœ‰æŠ“æ¡åŠ›", "æ•°é‡ä¸ç¬¦/å‘é”™è´§", "å¯¼è‡´è¡€æ¶²å¾ªç¯å—é˜»"
]

# =========================
# 2. AI æ¨¡å‹åŠ è½½
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

# =========================
# 3. æ ¸å¿ƒåŠŸèƒ½ï¼šåŠ¨æ€æ ‡ç­¾æå–
# =========================
def extract_dynamic_label(text, model, ngram_range=(2, 3)):
    """
    å½“è¯„è®ºä¸åŒ¹é…æ ‡å‡†åº“æ—¶ï¼Œä»åŸæ–‡ä¸­æå–æœ€æ ¸å¿ƒçš„çŸ­è¯­ä½œä¸ºæ–°æ ‡ç­¾
    åŸç†ï¼šKeyBERT ç®—æ³•ç®€åŒ–ç‰ˆ
    """
    try:
        # 1. ä½¿ç”¨ CountVectorizer æå–å€™é€‰çŸ­è¯­ (2-3ä¸ªè¯çš„ç»„åˆ)
        # stop_words='english' ä¼šè‡ªåŠ¨è¿‡æ»¤æ‰ the, is, at ç­‰æ— æ„ä¹‰è¯
        count = CountVectorizer(ngram_range=ngram_range, stop_words='english').fit([text])
        candidates = count.get_feature_names_out()
        
        if len(candidates) == 0:
            return "å…¶ä»–æœªåˆ†ç±»"

        # 2. ç¼–ç åŸæ–‡å’Œæ‰€æœ‰å€™é€‰çŸ­è¯­
        doc_embedding = model.encode([text])
        candidate_embeddings = model.encode(candidates)

        # 3. è®¡ç®—åŸæ–‡ä¸å€™é€‰çŸ­è¯­çš„ç›¸ä¼¼åº¦
        distances = util.cos_sim(doc_embedding, candidate_embeddings)
        
        # 4. å–æœ€ç›¸ä¼¼çš„é‚£ä¸ªçŸ­è¯­ä½œä¸ºæ ‡ç­¾
        keywords = [candidates[index] for index in distances.argsort()[0][-1:]]
        
        # å°†è‹±æ–‡çŸ­è¯­é¦–å­—æ¯å¤§å†™ï¼Œçœ‹èµ·æ¥æ›´åƒæ ‡ç­¾
        return keywords[0].title()
        
    except Exception:
        # å¦‚æœæ–‡æœ¬å¤ªçŸ­æˆ–æŠ¥é”™ï¼Œè¿”å›é»˜è®¤
        return "å…¶ä»–(æ–‡æœ¬è¿‡çŸ­)"

def semantic_classify_and_discover(df, model, match_threshold=0.45):
    """
    åŒå±‚é€»è¾‘ï¼š
    1. ä¼˜å…ˆåŒ¹é…æ ‡å‡†åº“ (ç›¸ä¼¼åº¦ > threshold)
    2. åŒ¹é…ä¸åˆ° -> åˆ¤æ–­æƒ…æ„Ÿ -> æå–åŸæ–‡çŸ­è¯­ä½œä¸ºæ–°æ ‡ç­¾
    """
    reviews = df['text'].tolist()
    
    # æ‰¹é‡ç¼–ç ï¼Œé€Ÿåº¦å¿«
    review_embeddings = model.encode(reviews, convert_to_tensor=True)
    pos_embeddings = model.encode(POS_LABELS, convert_to_tensor=True)
    neg_embeddings = model.encode(NEG_LABELS, convert_to_tensor=True)
    
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    pos_sims = util.cos_sim(review_embeddings, pos_embeddings)
    neg_sims = util.cos_sim(review_embeddings, neg_embeddings)
    
    final_labels = []
    is_new_label = [] # æ ‡è®°æ˜¯å¦æ˜¯æ–°å‘ç°çš„æ ‡ç­¾
    sentiment_types = []

    progress_bar = st.progress(0)
    total = len(df)
    
    for i in range(total):
        if i % 10 == 0: progress_bar.progress(i / total)

        rating = df.iloc[i]['rating']
        text = df.iloc[i]['text']
        
        # è·å–ä¸æ ‡å‡†åº“çš„æœ€ä½³åŒ¹é…
        best_pos_idx = torch.argmax(pos_sims[i]).item()
        best_pos_score = pos_sims[i][best_pos_idx].item()
        
        best_neg_idx = torch.argmax(neg_sims[i]).item()
        best_neg_score = neg_sims[i][best_neg_idx].item()
        
        label = None
        s_type = "Unknown"
        is_new = False

        # --- é€»è¾‘ A: åˆ¤å®šæƒ…æ„Ÿæ–¹å‘ ---
        # 1-3æ˜Ÿï¼šå·®è¯„ï¼›5æ˜Ÿï¼šå¥½è¯„ï¼›4æ˜Ÿï¼šçœ‹ç›¸ä¼¼åº¦
        is_negative = False
        if rating <= 3:
            is_negative = True
        elif rating == 4:
            if best_neg_score > best_pos_score: is_negative = True
            else: is_negative = False
        else:
            is_negative = False

        # --- é€»è¾‘ B: åŒ¹é…æˆ–å‘ç° ---
        
        if is_negative:
            s_type = "Negative"
            # 1. å°è¯•åŒ¹é…æ ‡å‡†å·®è¯„åº“
            if best_neg_score > match_threshold:
                label = NEG_LABELS[best_neg_idx]
            else:
                # 2. åŒ¹é…å¤±è´¥ï¼Œæ‰§è¡Œâ€œæ–°æ ‡ç­¾æŒ–æ˜â€
                label = extract_dynamic_label(text, model)
                is_new = True
        else:
            s_type = "Positive"
            # 1. å°è¯•åŒ¹é…æ ‡å‡†å¥½è¯„åº“
            if best_pos_score > match_threshold:
                label = POS_LABELS[best_pos_idx]
            else:
                # 2. åŒ¹é…å¤±è´¥ï¼Œæ‰§è¡Œâ€œæ–°æ ‡ç­¾æŒ–æ˜â€
                label = extract_dynamic_label(text, model)
                is_new = True
        
        final_labels.append(label)
        sentiment_types.append(s_type)
        is_new_label.append(is_new)

    progress_bar.empty()
    return final_labels, sentiment_types, is_new_label

# =========================
# 4. è¾…åŠ©å·¥å…·
# =========================
def load_file(f):
    if f.name.lower().endswith(".csv"):
        try: return pd.read_csv(f, encoding="utf-8")
        except: return pd.read_csv(f, encoding="gbk")
    return pd.read_excel(f)

def parse_rating(x):
    if pd.isna(x): return np.nan
    m = re.search(r"(\d+(\.\d+)?)", str(x))
    return float(m.group(1)) if m else np.nan

# =========================
# 5. ä¸»ç¨‹åº UI
# =========================
st.title("â›ï¸ æ™ºèƒ½è¯„è®ºæ ‡ç­¾æŒ–æ˜ç³»ç»Ÿ (æ ‡å‡†åº“ + æ–°è¯å‘ç°)")
st.markdown("""
**æ ¸å¿ƒé€»è¾‘æ›´æ–°ï¼š**
1. **ä¸¥æ ¼åŒ¹é…**ï¼šé¦–å…ˆæ£€æŸ¥è¯„è®ºæ˜¯å¦ç¬¦åˆæ‚¨è®¾å®šçš„ `POS_LABELS` å’Œ `NEG_LABELS`ã€‚
2. **æ–°è¯å‘ç°**ï¼šå¦‚æœä¸ç¬¦åˆï¼ŒAI ä¼šè‡ªåŠ¨åˆ†ææ˜¯å¥½è¯„è¿˜æ˜¯å·®è¯„ï¼Œå¹¶**ä»è¯„è®ºä¸­æå–æ ¸å¿ƒçŸ­è¯­**ä½œä¸ºæ–°æ ‡ç­¾ã€‚
""")

with st.spinner("æ­£åœ¨åŠ è½½ AI å¼•æ“..."):
    model = load_model()

uploaded = st.file_uploader("ä¸Šä¼ è¯„è®ºæ–‡ä»¶", type=["csv", "xlsx"])

if uploaded:
    with st.spinner('AI æ­£åœ¨é€è¡Œåˆ†æï¼šåŒ¹é…æ ‡å‡†åº“ æˆ– æŒ–æ˜æ–°æ ‡ç­¾...'):
        df = load_file(uploaded)
        
        # å­—æ®µè¯†åˆ«
        all_cols = df.columns.tolist()
        rating_col = next((c for c in all_cols if "æ˜Ÿ" in c or "rating" in c.lower()), all_cols[0])
        text_col = next((c for c in all_cols if "å†…å®¹" in c or "review" in c.lower()), all_cols[1])
        
        # æ¸…æ´—
        df["rating"] = df[rating_col].apply(parse_rating).round().astype(int)
        df = df[df["rating"].between(1, 5)]
        df["text"] = df[text_col].astype(str).fillna("")
        
        # === æ ¸å¿ƒè¿ç®— ===
        labels, sentiments, is_new = semantic_classify_and_discover(df, model)
        df["Tag_Label"] = labels
        df["Sentiment_Type"] = sentiments
        df["Is_New_Tag"] = is_new # æ ‡è®°æ˜¯å¦æ˜¯æ–°å‘ç°çš„æ ‡ç­¾
        
    st.success(f"âœ… å¤„ç†å®Œæˆï¼å‘ç° {sum(is_new)} æ¡è¯„è®ºäº§ç”Ÿäº†æ–°æ ‡ç­¾ã€‚")

    # =========================
    # æ¨¡å— A: æ ‡ç­¾åˆ†å¸ƒæ¦‚è§ˆ
    # =========================
    st.markdown("---")
    st.header("1. æ ‡ç­¾åˆ†å¸ƒæ¦‚è§ˆ")
    
    # ç»Ÿè®¡ Top æ ‡ç­¾
    top_labels = df["Tag_Label"].value_counts().head(20).reset_index()
    top_labels.columns = ["Label", "Count"]
    
    # æ ‡è®°å“ªäº›æ˜¯æ–°æ ‡ç­¾ä»¥ä¾¿åœ¨å›¾ä¸­åŒºåˆ†
    std_set = set(POS_LABELS + NEG_LABELS)
    top_labels["Type"] = top_labels["Label"].apply(lambda x: "æ ‡å‡†åº“" if x in std_set else "âœ¨æ–°å‘ç°")
    
    fig_bar = px.bar(top_labels, x="Count", y="Label", orientation='h', color="Type",
                     title="çƒ­é—¨æ ‡ç­¾æ’è¡Œ (åŒºåˆ†æ ‡å‡†åº“ä¸æ–°å‘ç°)",
                     color_discrete_map={"æ ‡å‡†åº“": "#1f77b4", "âœ¨æ–°å‘ç°": "#ff7f0e"})
    fig_bar.update_layout(yaxis={'categoryorder':'total ascending'})
    st.plotly_chart(fig_bar, use_container_width=True)

    # =========================
    # æ¨¡å— B: æ–°å‘ç°çš„ç—›ç‚¹ (å·®è¯„æŒ–æ˜)
    # =========================
    st.markdown("---")
    st.header("2. ğŸ” æ–°å‘ç°çš„æ½œåœ¨ç—›ç‚¹ (ä¸åœ¨æ ‡å‡†åº“ä¸­)")
    st.caption("AI è¯†åˆ«å‡ºè¿™äº›å·®è¯„ä¸å±äºæ‚¨çš„æ ‡å‡†åº“ï¼Œå¹¶æå–äº†ä»¥ä¸‹æ ¸å¿ƒçŸ­è¯­ï¼š")
    
    new_neg_df = df[(df["Is_New_Tag"] == True) & (df["Sentiment_Type"] == "Negative")]
    
    if not new_neg_df.empty:
        # ç»Ÿè®¡æ–°å‘ç°çš„å·®è¯„æ ‡ç­¾
        new_neg_counts = new_neg_df["Tag_Label"].value_counts().reset_index()
        new_neg_counts.columns = ["New Issue", "Count"]
        
        c1, c2 = st.columns([1, 2])
        with c1:
            st.dataframe(new_neg_counts.head(10), hide_index=True)
        with c2:
            sel_new_issue = st.selectbox("é€‰æ‹©ä¸€ä¸ªæ–°å‘ç°çš„é—®é¢˜æŸ¥çœ‹åŸå£°:", new_neg_counts["New Issue"].unique())
            
            st.markdown(f"**ç”¨æˆ·å…³äº '{sel_new_issue}' çš„åŸè¯:**")
            reviews = new_neg_df[new_neg_df["Tag_Label"] == sel_new_issue]["text"].head(5)
            for r in reviews:
                st.info(r)
    else:
        st.success("æ‚¨çš„æ ‡å‡†å·®è¯„åº“è¦†ç›–äº†æ‰€æœ‰å·®è¯„ï¼Œæœªå‘ç°æ–°é—®é¢˜ï¼")

    # =========================
    # æ¨¡å— C: è¯¦ç»†æ•°æ®è¡¨
    # =========================
    st.markdown("---")
    st.header("3. è¯¦ç»†åˆ†ç±»æ•°æ®")
    
    # å¢åŠ ç­›é€‰å™¨
    filter_type = st.radio("ç­›é€‰æŸ¥çœ‹:", ["å…¨éƒ¨", "ä»…æŸ¥çœ‹æ–°å‘ç°çš„æ ‡ç­¾", "ä»…æŸ¥çœ‹æ ‡å‡†åº“åŒ¹é…"])
    
    view_df = df
    if filter_type == "ä»…æŸ¥çœ‹æ–°å‘ç°çš„æ ‡ç­¾":
        view_df = df[df["Is_New_Tag"] == True]
    elif filter_type == "ä»…æŸ¥çœ‹æ ‡å‡†åº“åŒ¹é…":
        view_df = df[df["Is_New_Tag"] == False]
        
    st.dataframe(view_df[["rating", "Sentiment_Type", "Tag_Label", "Is_New_Tag", "text"]], height=400)

    # ä¸‹è½½
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Analysis')
    
    st.download_button(
        label="â¬‡ï¸ ä¸‹è½½å®Œæ•´ Excel æŠ¥è¡¨",
        data=buffer.getvalue(),
        file_name="smart_tag_discovery_report.xlsx",
        mime="application/vnd.ms-excel"
    )
