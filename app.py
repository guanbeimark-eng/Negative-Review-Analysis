import streamlit as st
import pandas as pd
import json
import uuid
import re
import numpy as np

# ======================================================
# 0. é¡µé¢é…ç½® & ç™»å½•
# ======================================================
st.set_page_config(
    page_title="LLM è¯„è®ºæ‰“æ ‡ç³»ç»Ÿï¼ˆå¯è§†åŒ–åˆ—æ˜ å°„ + å·®è¯„å æ¯”ä¿®å¤ç‰ˆï¼‰",
    page_icon="ğŸ·ï¸",
    layout="wide"
)

ACCESS_PASSWORD = "admin123"

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state.get("password_input") == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop()

# ======================================================
# 1. Session State
# ======================================================
defaults = {
    "raw_df": None,
    "preview_main_df": None,     # é¢„è§ˆæ€ï¼ˆä¸»è¡¨æ¸…æ´—åï¼Œå«rating_intç­‰ï¼‰
    "preview_norm_df": None,     # é¢„è§ˆæ€ï¼ˆå½’ä¸€åŒ–å id/rating/textï¼‰
    "main_df": None,             # ç¡®è®¤æ€ä¸»è¡¨
    "normalized_df": None,       # ç¡®è®¤æ€å½’ä¸€åŒ–è¡¨
    "id_col_in_main": None,      # ä¸»è¡¨é‡ŒçœŸå®IDåˆ—åï¼ˆsys_uuid or ç”¨æˆ·é€‰åˆ—ï¼‰
    "mapping_locked": False,

    "tag_config": {"pos": [], "neg": [], "all": []},
    "generated_batches": []
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ======================================================
# 2. å·¥å…·å‡½æ•°
# ======================================================
def load_file(f):
    name = f.name.lower()
    if name.endswith(".csv"):
        try:
            return pd.read_csv(f, encoding="utf-8")
        except UnicodeDecodeError:
            return pd.read_csv(f, encoding="gbk")
    return pd.read_excel(f)

def parse_rating(x):
    """
    å…¼å®¹ï¼š
    - '4.0 out of 5 stars'
    - 'Rated 3 out of 5'
    - '5'
    - 4.0
    """
    if pd.isna(x):
        return np.nan
    s = str(x)
    m = re.search(r"(\d+(?:\.\d+)?)", s)
    if not m:
        return np.nan
    try:
        return float(m.group(1))
    except:
        return np.nan

def normalize_polarity(x):
    s = str(x).strip().lower()
    if any(k in s for k in ["positive", "pos", "good", "å¥½", "æ­£"]):
        return "positive"
    if any(k in s for k in ["negative", "neg", "bad", "å·®", "è´Ÿ"]):
        return "negative"
    return ""

def safe_parse_json(text):
    if not text:
        return None
    clean = text.replace("```json", "").replace("```", "").strip()
    if not clean:
        return None
    # å…ˆæ•´ä½“è§£æ
    try:
        return json.loads(clean)
    except:
        pass
    # å¤šæ®µç²˜è´´ï¼šæŒ‰ç©ºè¡Œåˆ‡å¼€å°è¯•åˆå¹¶
    parts = [p.strip() for p in clean.split("\n\n") if p.strip()]
    merged = []
    ok = False
    for p in parts:
        try:
            obj = json.loads(p)
            if isinstance(obj, list):
                merged.extend(obj)
                ok = True
        except:
            continue
    return merged if ok else None

def validate_label(label, allowed_set: set):
    if label is None:
        return ""
    lab = str(label).strip()
    return lab if lab in allowed_set else ""

# ======================================================
# 3. é¡µé¢ç»“æ„
# ======================================================
st.title("ğŸ·ï¸ è¯„è®ºæ•°æ®æ‰“æ ‡ç³»ç»Ÿï¼ˆåˆ—æ˜ å°„å¯è§†åŒ– + å·®è¯„å æ¯”ä¿®å¤ç‰ˆï¼‰")

tab1, tab2, tab3, tab4 = st.tabs([
    "1ï¸âƒ£ æ•°æ®åˆ—æ˜ å°„ï¼ˆå¯è§†åŒ–ï¼‰",
    "2ï¸âƒ£ è¯„ä»·åº“é…ç½®",
    "3ï¸âƒ£ Prompt ç”Ÿæˆï¼ˆ4æ˜Ÿä¼˜å…ˆå·®è¯„ï¼‰",
    "4ï¸âƒ£ å›å¡« & å¯¼å‡º"
])

# ======================================================
# Tab 1ï¼šæ•°æ®åˆ—æ˜ å°„ï¼ˆé€‰æ‹© â†’ é¢„è§ˆ â†’ ç¡®è®¤é”å®šï¼‰
# ======================================================
with tab1:
    st.header("Step 1ï¼šæ•°æ®å¯¼å…¥ & åˆ—æ˜ å°„ï¼ˆæŒ‰é’®åŒ– + å¯è§†åŒ–ï¼‰")

    uploaded = st.file_uploader("ä¸Šä¼ è¯„è®ºæ•°æ®ï¼ˆCSV / Excelï¼‰", type=["csv", "xlsx"])

    if uploaded:
        df_raw = load_file(uploaded)
        st.session_state.raw_df = df_raw

        st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼šå…±åŒ…å« {len(df_raw)} è¡Œï¼ˆåŸå§‹è¡Œæ•°ï¼‰")
        st.dataframe(df_raw.head(5))

        cols = df_raw.columns.tolist()

        st.markdown("---")
        st.subheader("ğŸ”§ é€‰æ‹©å…³é”®å­—æ®µï¼ˆå…ˆé€‰ï¼Œåé¢„è§ˆï¼Œå†ç¡®è®¤ï¼‰")

        c1, c2, c3, c4, c5 = st.columns(5)
        with c1:
            col_rating = st.selectbox("â­ æ˜Ÿçº§åˆ— (rating)", cols, disabled=st.session_state.mapping_locked)
        with c2:
            col_title = st.selectbox("ğŸ“ æ ‡é¢˜åˆ—ï¼ˆå¯é€‰ï¼‰", ["--ä¸ä½¿ç”¨--"] + cols, disabled=st.session_state.mapping_locked)
        with c3:
            col_content = st.selectbox("ğŸ“„ å†…å®¹åˆ— (content)", cols, disabled=st.session_state.mapping_locked)
        with c4:
            col_id = st.selectbox("ğŸ†” å”¯ä¸€IDåˆ—", ["-- è‡ªåŠ¨ç”Ÿæˆ UUID --"] + cols, disabled=st.session_state.mapping_locked)
        with c5:
            col_date = st.selectbox("ğŸ“… æ—¶é—´åˆ—ï¼ˆå¯é€‰ï¼‰", ["--ä¸ä½¿ç”¨--"] + cols, disabled=st.session_state.mapping_locked)

        st.markdown("---")
        c_btn1, c_btn2, c_btn3 = st.columns([1,1,2])

        with c_btn1:
            preview_clicked = st.button("ğŸ” é¢„è§ˆæ˜ å°„æ•ˆæœ", disabled=st.session_state.mapping_locked)
        with c_btn2:
            confirm_clicked = st.button("âœ… ç¡®è®¤å¹¶é”å®šæ˜ å°„", type="primary", disabled=(st.session_state.preview_norm_df is None or st.session_state.mapping_locked))
        with c_btn3:
            reset_clicked = st.button("â™»ï¸ è§£é™¤é”å®š/é‡æ–°æ˜ å°„", disabled=not st.session_state.mapping_locked)

        if reset_clicked:
            st.session_state.mapping_locked = False
            st.session_state.preview_main_df = None
            st.session_state.preview_norm_df = None
            st.session_state.main_df = None
            st.session_state.normalized_df = None
            st.session_state.id_col_in_main = None
            st.success("å·²è§£é™¤é”å®šï¼Œå¯ä»¥é‡æ–°é€‰æ‹©åˆ—å¹¶é¢„è§ˆã€‚")

        if preview_clicked:
            tmp = df_raw.copy()

            # ---------- 1) rating è§£æï¼ˆå…³é”®ä¿®å¤ï¼‰ ----------
            tmp["rating_numeric"] = tmp[col_rating].apply(parse_rating)
            invalid_rating_cnt = int(tmp["rating_numeric"].isna().sum())

            # å…ˆä¿ç•™ç»Ÿè®¡ä¿¡æ¯ï¼Œå†è¿‡æ»¤
            valid = tmp.dropna(subset=["rating_numeric"]).copy()
            valid["rating_int"] = valid["rating_numeric"].round().astype(int)
            valid = valid[valid["rating_int"].between(1, 5)]

            # ---------- 2) æ—¶é—´è§£æï¼ˆå¯é€‰ï¼‰ ----------
            time_parse_success = False
            if col_date != "--ä¸ä½¿ç”¨--":
                valid["date_parsed"] = pd.to_datetime(valid[col_date], errors="coerce")
                time_parse_success = valid["date_parsed"].notna().sum() > 0

            # ---------- 3) ID å¤„ç† ----------
            if col_id.startswith("--"):
                valid["sys_uuid"] = [str(uuid.uuid4())[:8] for _ in range(len(valid))]
                id_col_in_main = "sys_uuid"
            else:
                valid[col_id] = valid[col_id].astype(str)
                id_col_in_main = col_id

            # ---------- 4) text æ‹¼æ¥ï¼ˆæ ‡é¢˜å¯é€‰ï¼‰ ----------
            if col_title != "--ä¸ä½¿ç”¨--":
                valid["__text_joined__"] = (
                    valid[col_title].fillna("").astype(str).str.strip()
                    + " | "
                    + valid[col_content].fillna("").astype(str).str.strip()
                ).str.strip(" |")
                text_col = "__text_joined__"
            else:
                text_col = col_content

            # é¢„è§ˆå½’ä¸€åŒ–è¡¨ï¼ˆç»™ LLM çš„è¾“å…¥ï¼‰
            norm = valid[[id_col_in_main, "rating_int", text_col]].rename(columns={
                id_col_in_main: "id",
                "rating_int": "rating",
                text_col: "text"
            }).copy()

            # ä¿å­˜åˆ° sessionï¼ˆé¢„è§ˆæ€ï¼‰
            st.session_state.preview_main_df = valid
            st.session_state.preview_norm_df = norm
            st.session_state.id_col_in_main = id_col_in_main

            # ========== å¯è§†åŒ–é¢„è§ˆåŒº ==========
            st.subheader("âœ… é¢„è§ˆç»“æœï¼ˆç¡®è®¤æ— è¯¯å†ç‚¹â€œé”å®šæ˜ å°„â€ï¼‰")

            raw_total = len(df_raw)
            valid_total = len(valid)

            neg_cnt = int((valid["rating_int"] <= 3).sum())
            neg_rate = (neg_cnt / valid_total * 100) if valid_total else 0

            severe_neg_cnt = int((valid["rating_int"] <= 2).sum())
            severe_neg_rate = (severe_neg_cnt / valid_total * 100) if valid_total else 0

            m1, m2, m3, m4, m5 = st.columns(5)
            m1.metric("åŸå§‹è¡Œæ•°", raw_total)
            m2.metric("æœ‰æ•ˆè¯„åˆ†è¡Œæ•°", valid_total)
            m3.metric("è¯„åˆ†è§£æå¤±è´¥è¡Œæ•°", invalid_rating_cnt)
            m4.metric("å·®è¯„å æ¯”(â‰¤3â­)", f"{neg_rate:.1f}%")
            m5.metric("ä¸¥é‡å·®è¯„(â‰¤2â­)", f"{severe_neg_rate:.1f}%")

            st.markdown("### â­ æ˜Ÿçº§åˆ†å¸ƒï¼ˆ1â€“5ï¼‰")
            dist = valid["rating_int"].value_counts().reindex([1,2,3,4,5], fill_value=0).sort_index()
            st.bar_chart(dist)

            st.markdown("### ğŸ†” ID å®‰å…¨æ€§æ£€æŸ¥")
            cc1, cc2, cc3 = st.columns(3)
            cc1.metric("IDæ˜¯å¦å”¯ä¸€", "âœ…" if norm["id"].is_unique else "âŒ")
            cc2.metric("IDç©ºå€¼æ•°", int(norm["id"].isna().sum()))
            cc3.metric("ç¤ºä¾‹ID", str(norm["id"].iloc[0]) if len(norm) else "N/A")

            if not norm["id"].is_unique:
                st.error("âš ï¸ ä½ é€‰æ‹©çš„IDåˆ—ä¸å”¯ä¸€ï¼Œä¼šå¯¼è‡´å›å¡«é”™ä¹±ã€‚è¯·æ¢ä¸€ä¸ªå”¯ä¸€åˆ—æˆ–ä½¿ç”¨è‡ªåŠ¨UUIDã€‚")

            st.markdown("### ğŸ“ é€å…¥ LLM çš„æ–‡æœ¬é¢„è§ˆï¼ˆå‰ 5 æ¡ï¼‰")
            st.dataframe(norm.head(5))

            if time_parse_success:
                st.markdown("### ğŸ“ˆ è¯„è®ºæ—¶é—´è¶‹åŠ¿ï¼ˆæœˆåº¦ï¼‰")
                try:
                    ts = valid.dropna(subset=["date_parsed"]).set_index("date_parsed").resample("M").size()
                    st.line_chart(ts)
                except Exception:
                    st.info("æ—¶é—´è¶‹åŠ¿ç»˜åˆ¶å¤±è´¥ï¼ˆä½†ä¸å½±å“å…¶å®ƒåŠŸèƒ½ï¼‰")
            else:
                st.info("æœªé€‰æ‹©æ—¶é—´åˆ—æˆ–æ—¶é—´è§£æå¤±è´¥ï¼šå·²è·³è¿‡è¶‹åŠ¿åˆ†æã€‚")

        if confirm_clicked:
            # é”å®šï¼šå°†é¢„è§ˆæ€å†™å…¥æ­£å¼æ€
            st.session_state.main_df = st.session_state.preview_main_df.copy()
            st.session_state.normalized_df = st.session_state.preview_norm_df.copy()
            st.session_state.mapping_locked = True
            st.success("âœ… å·²é”å®šåˆ—æ˜ å°„ã€‚ç°åœ¨å¯ä»¥è¿›å…¥ Step 2 é…ç½®è¯„ä»·åº“ã€‚")

# ======================================================
# Tab 2ï¼šè¯„ä»·åº“é…ç½®
# ======================================================
with tab2:
    st.header("Step 2ï¼šå¯¼å…¥è¯„ä»·åº“æ ‡ç­¾ï¼ˆlabel + polarityï¼‰")

    st.info("å»ºè®®è¯„ä»·åº“è¡¨åŒ…å«ï¼šlabelï¼ˆæ ‡ç­¾åï¼‰ã€polarityï¼ˆpositive/negative æˆ– å¥½è¯„/å·®è¯„ï¼‰")

    tag_file = st.file_uploader("ä¸Šä¼ è¯„ä»·åº“ï¼ˆCSV/Excelï¼‰", type=["csv", "xlsx"])
    if tag_file:
        tag_df = load_file(tag_file)
        st.dataframe(tag_df.head(10))

        c1, c2 = st.columns(2)
        with c1:
            lbl_col = st.selectbox("æ ‡ç­¾åˆ—(label)", tag_df.columns)
        with c2:
            pol_col = st.selectbox("ææ€§åˆ—(polarity)", tag_df.columns)

        if st.button("åŠ è½½è¯„ä»·åº“"):
            tmp = tag_df.copy()
            tmp["pol_norm"] = tmp[pol_col].apply(normalize_polarity)

            pos = tmp[tmp["pol_norm"] == "positive"][lbl_col].dropna().astype(str).unique().tolist()
            neg = tmp[tmp["pol_norm"] == "negative"][lbl_col].dropna().astype(str).unique().tolist()

            st.session_state.tag_config = {
                "pos": pos,
                "neg": neg,
                "all": list(dict.fromkeys(pos + neg))
            }
            st.success(f"âœ… è¯„ä»·åº“åŠ è½½æˆåŠŸï¼šå¥½è¯„ {len(pos)} ä¸ªï¼Œå·®è¯„ {len(neg)} ä¸ª")

    st.markdown("---")
    st.subheader("å½“å‰å·²åŠ è½½æ ‡ç­¾é¢„è§ˆ")
    st.write({
        "å¥½è¯„æ ‡ç­¾æ•°": len(st.session_state.tag_config["pos"]),
        "å·®è¯„æ ‡ç­¾æ•°": len(st.session_state.tag_config["neg"])
    })
    with st.expander("æŸ¥çœ‹å¥½è¯„æ ‡ç­¾"):
        st.write(st.session_state.tag_config["pos"])
    with st.expander("æŸ¥çœ‹å·®è¯„æ ‡ç­¾"):
        st.write(st.session_state.tag_config["neg"])

# ======================================================
# Tab 3ï¼šPrompt ç”Ÿæˆï¼ˆ4æ˜Ÿä¼˜å…ˆå·®è¯„ç‚¹ï¼‰
# ======================================================
with tab3:
    st.header("Step 3ï¼šç”Ÿæˆ Promptï¼ˆ4 æ˜Ÿä¼˜å…ˆå·®è¯„ç‚¹ï¼‰")

    if st.session_state.normalized_df is None or not st.session_state.mapping_locked:
        st.warning("è¯·å…ˆåœ¨ Step 1 å®Œæˆå¹¶é”å®šåˆ—æ˜ å°„ã€‚")
        st.stop()

    if (not st.session_state.tag_config["pos"]) or (not st.session_state.tag_config["neg"]):
        st.warning("è¯·å…ˆåœ¨ Step 2 åŠ è½½è¯„ä»·åº“ï¼ˆéœ€è¦åŒæ—¶æœ‰å¥½è¯„/å·®è¯„æ ‡ç­¾ï¼‰ã€‚")
        st.stop()

    batch_size = st.number_input("æ¯æ‰¹æ¡æ•°", value=30, min_value=10, max_value=200, step=10)

    def build_prompt(data_chunk, mode):
        pos = ", ".join([f'"{t}"' for t in st.session_state.tag_config["pos"]])
        neg = ", ".join([f'"{t}"' for t in st.session_state.tag_config["neg"]])

        system = (
            "You are an expert review tagger.\n"
            "You MUST choose labels ONLY from the provided tag libraries.\n"
            "Return STRICT JSON only (no explanations, no extra text).\n"
            "Output schema: [{\"id\":\"...\",\"label\":\"\"}].\n"
            "If no suitable tag, label must be empty string \"\".\n"
        )

        if mode == "1-3":
            task = f"""
TASK:
These are 1-3 star reviews.
You MUST choose from NEGATIVE TAG LIBRARY only.

NEGATIVE TAG LIBRARY:
[{neg}]
"""
        elif mode == "5":
            task = f"""
TASK:
These are 5 star reviews.
You MUST choose from POSITIVE TAG LIBRARY only.

POSITIVE TAG LIBRARY:
[{pos}]
"""
        else:  # 4
            task = f"""
TASK:
These are 4 star reviews. PRIORITIZE complaints.
Rule:
1) If review contains ANY complaint/negative point, choose from NEGATIVE TAG LIBRARY.
2) Otherwise choose from POSITIVE TAG LIBRARY.
3) If still no suitable tag, output "".

NEGATIVE TAG LIBRARY:
[{neg}]

POSITIVE TAG LIBRARY:
[{pos}]
"""

        data = "DATA (JSON):\n" + json.dumps(data_chunk, ensure_ascii=False, indent=2)
        return f"{system}\n{task}\n{data}"

    if st.button("ç”Ÿæˆ Prompt"):
        df = st.session_state.normalized_df
        batches = []

        groups = {
            "1-3": df[df["rating"] <= 3],
            "4": df[df["rating"] == 4],
            "5": df[df["rating"] == 5],
        }

        for mode, gdf in groups.items():
            if gdf.empty:
                continue
            records = gdf.to_dict("records")
            for i in range(0, len(records), int(batch_size)):
                chunk = records[i:i+int(batch_size)]
                batches.append({
                    "title": f"[{mode}æ˜Ÿ] æ‰¹æ¬¡ {i//int(batch_size)+1}ï¼ˆ{len(chunk)}æ¡ï¼‰",
                    "prompt": build_prompt(chunk, mode)
                })

        st.session_state.generated_batches = batches
        st.success(f"âœ… å·²ç”Ÿæˆ {len(batches)} ä¸ªä»»åŠ¡åŒ…")

    for b in st.session_state.generated_batches:
        with st.expander(b["title"]):
            st.text_area("Promptï¼ˆå¤åˆ¶ç»™æ¨¡å‹ï¼‰", b["prompt"], height=280)
            st.caption("æç¤ºï¼šè®©æ¨¡å‹åªè¿”å› JSONï¼Œé¿å…å¤¹å¸¦è§£é‡Šå¯¼è‡´è§£æå¤±è´¥ã€‚")

# ======================================================
# Tab 4ï¼šç»“æœå›å¡« & å¯¼å‡º
# ======================================================
with tab4:
    st.header("Step 4ï¼šå›å¡«ç»“æœï¼ˆä¸¥æ ¼æ ¡éªŒåº“å†…æ ‡ç­¾ï¼‰& å¯¼å‡º")

    if st.session_state.normalized_df is None:
        st.warning("è¯·å…ˆå®Œæˆ Step 1 & Step 3ã€‚")
        st.stop()

    allowed_set = set(st.session_state.tag_config["all"])

    json_text = st.text_area("ç²˜è´´ LLM è¿”å› JSONï¼ˆå¯ä¸€æ¬¡ç²˜è´´å¤šæ‰¹æ¬¡ï¼‰", height=220)

    if st.button("åˆå¹¶ç»“æœ"):
        data = safe_parse_json(json_text)
        if not data or not isinstance(data, list):
            st.error("JSON è§£æå¤±è´¥ï¼šè¯·ç¡®ä¿è¿”å›æ ¼å¼ä¸º listï¼Œä¾‹å¦‚ï¼š[{'id':'xxx','label':'...'}]")
        else:
            res_df = pd.DataFrame(data)
            if "id" not in res_df.columns or "label" not in res_df.columns:
                st.error("è¿”å› JSON å¿…é¡»åŒ…å« id å’Œ label å­—æ®µã€‚")
            else:
                res_df["id"] = res_df["id"].astype(str)
                # ä¸¥æ ¼æ ¡éªŒï¼šåº“å¤–æ ‡ç­¾ç½®ç©º
                res_df["label"] = res_df["label"].apply(lambda x: validate_label(x, allowed_set))

                id_map = dict(zip(res_df["id"], res_df["label"]))

                df = st.session_state.normalized_df.copy()
                if "AI_Label" not in df.columns:
                    df["AI_Label"] = ""

                df["AI_Label"] = df["id"].map(id_map).fillna(df["AI_Label"]).astype(str)
                st.session_state.normalized_df = df

                st.success(f"âœ… åˆå¹¶å®Œæˆï¼šæœ¬æ¬¡åˆå¹¶ {len(res_df)} æ¡ï¼ˆåº“å¤–æ ‡ç­¾å·²è‡ªåŠ¨ç½®ç©ºï¼‰")
                st.dataframe(df.head(20))

    st.markdown("---")
    st.subheader("å¯¼å‡ºç»“æœ")

    if st.session_state.normalized_df is not None:
        out_csv = st.session_state.normalized_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("â¬‡ï¸ ä¸‹è½½æ‰“æ ‡ç»“æœ CSVï¼ˆnormalizedï¼‰", out_csv, "tagged_reviews_normalized.csv", "text/csv")

    # å¦‚æœä½ ä¹Ÿæƒ³å¯¼å‡ºä¸»è¡¨ï¼ˆå¸¦åŸå­—æ®µ + AI_Labelï¼‰ï¼Œå¯ä»¥åšä¸€æ¬¡ merge
    if st.session_state.main_df is not None and st.session_state.normalized_df is not None:
        id_col = st.session_state.id_col_in_main  # ä¸»è¡¨é‡Œçš„IDåˆ—å
        main = st.session_state.main_df.copy()
        main[id_col] = main[id_col].astype(str)

        lab = st.sessio
