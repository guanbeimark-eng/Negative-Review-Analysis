import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from sentence_transformers import SentenceTransformer, util
import torch
import re
import io
import warnings

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings('ignore')

# =========================
# 0. é¡µé¢é…ç½®ä¸å­—ä½“ä¿®å¤
# =========================
st.set_page_config(
    page_title="AI å…¨ç»´è¯„è®ºåˆ†æçœ‹æ¿ (Pro Ver.)",
    page_icon="ğŸ“Š",
    layout="wide"
)

# --- å­—ä½“è‡ªåŠ¨é…ç½®é€»è¾‘ (é˜²æ­¢äº‘ç«¯ä¸­æ–‡ä¹±ç ) ---
def configure_matplotlib_font():
    """
    å°è¯•æ‰¾åˆ°ç³»ç»Ÿå¯ç”¨çš„ä¸­æ–‡å­—ä½“ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™å›é€€åˆ°é»˜è®¤
    """
    # å¸¸è§ä¸­æ–‡å­—ä½“åˆ—è¡¨ (Windows, Mac, Linux)
    font_candidates = ['SimHei', 'Microsoft YaHei', 'PingFang SC', 'Heiti TC', 'WenQuanYi Micro Hei', 'Droid Sans Fallback']
    
    system_fonts = set(f.name for f in fm.fontManager.ttflist)
    found_font = None
    
    for f in font_candidates:
        if f in system_fonts:
            found_font = f
            break
            
    if found_font:
        plt.rcParams['font.sans-serif'] = [found_font] + plt.rcParams['font.sans-serif']
    else:
        # å¦‚æœå®åœ¨æ²¡æ‰¾åˆ°ï¼Œå°è¯•è®¾ç½®ä¸º sans-serifï¼Œè‡³å°‘æ˜¾ç¤ºè‹±æ–‡
        plt.rcParams['font.sans-serif'] = ['sans-serif']
        
    plt.rcParams['axes.unicode_minus'] = False # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

configure_matplotlib_font()

# --- è®¿é—®å¯†ç  ---
ACCESS_PASSWORD = "admin123" 

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state["password_input"] == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop() 

# =========================
# 1. æ ‡ç­¾åº“å®šä¹‰ (å›ºå®šé›†åˆ)
# =========================
POS_LABELS_LIST = [
    "é¢æ–™èˆ’é€‚", "è´¨é‡å¾ˆå¥½", "æœ‰åŠ©äºé”»ç‚¼", "æœ‰åŠ©äºç¼“è§£ç–¼ç—›", "ä¿æš–", "èˆ’é€‚è´´åˆ", 
    "æœ‰å‹ç¼©æ„Ÿ", "æŠ“æ¡å¼æœ‰æ•ˆ", "åˆèº«", "æœ‰åŠ©äºå…³èŠ‚ç‚/æ‰³æœºæŒ‡", "å¢åŠ æ‰‹æŒ‡çµæ´»", 
    "ä¿ƒè¿›è¡€æ¶²å¾ªç¯", "è€ç”¨", "ç¼“è§£ä¸é€‚", "è½»ç›ˆ", "è¦†ç›–æ•´ä¸ªæ‰‹æŒ‡", "æœ‰åŠ©äºé˜²æ­¢å—ä¼¤"
]

NEG_LABELS_LIST = [
    "æ— æ•ˆ/æ²¡æœ‰ä½œç”¨", "ç¼çº¿å¼€è£‚/ç ´æŸ", "æ”¶åˆ°äºŒæ‰‹/è„æ±¡", "é¢æ–™è´¨é‡å·®/å»‰ä»·", 
    "å°ºç å¤ªå°/å¤ªç´§", "å°ºç å¤ªå¤§/å¤ªæ¾", "æ¥ç¼å¤„ç£¨æ‰‹/ä¸é€‚", "ä¸è€ç”¨/ä¸€æ¬¡æ€§", 
    "è¿‡æ•/çš®ç–¹/å‘ç—’", "å¤ªæ»‘/æ²¡æœ‰æŠ“æ¡åŠ›", "æ•°é‡ä¸ç¬¦/å‘é”™è´§", "å¯¼è‡´è¡€æ¶²å¾ªç¯å—é˜»"
]

# =========================
# 2. AI æ¨¡å‹åŠ è½½
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# =========================
# 3. æ ¸å¿ƒ NLP å¼•æ“
# =========================
def split_into_sentences(text):
    """æ‹†å¥é€»è¾‘"""
    if not isinstance(text, str): return []
    sentences = re.split(r'[.!?;ã€‚ï¼ï¼Ÿï¼›\n]+', text)
    return [s.strip() for s in sentences if len(s.strip()) > 1]

def analyze_single_review(row_idx, rating, date_val, full_text, model, threshold=0.40):
    """å•æ¡è¯„è®ºæ·±åº¦æ‹†è§£"""
    sentences = split_into_sentences(full_text)
    analyzed_results = []
    
    pos_embeddings = model.encode(POS_LABELS_LIST, convert_to_tensor=True)
    neg_embeddings = model.encode(NEG_LABELS_LIST, convert_to_tensor=True)
    
    # åŸºäºæ˜Ÿçº§çš„åŸºå‡†æƒ…æ„Ÿ
    review_polarity_base = "negative" if rating <= 3 else "positive"

    # æ— æ³•æ‹†å¥æˆ–ç©ºè¯„è®ºå¤„ç†
    if not sentences:
        fallback_label = "å·®è¯„å…¶ä»–" if review_polarity_base == "negative" else "å¥½è¯„å…¶ä»–"
        return [{
            "review_id": row_idx,
            "date": date_val,
            "rating": rating,
            "original_review": full_text,
            "sentence": full_text[:50], # æˆªå–éƒ¨åˆ†ä½œä¸ºå±•ç¤º
            "polarity": review_polarity_base,
            "label": fallback_label,
            "evidence": full_text,
            "confidence": 0.5
        }]

    for sent in sentences:
        sent_embedding = model.encode(sent, convert_to_tensor=True)
        pos_scores = util.cos_sim(sent_embedding, pos_embeddings)[0]
        neg_scores = util.cos_sim(sent_embedding, neg_embeddings)[0]

        best_pos_score = torch.max(pos_scores).item()
        best_pos_idx = torch.argmax(pos_scores).item()
        best_neg_score = torch.max(neg_scores).item()
        best_neg_idx = torch.argmax(neg_scores).item()

        matched_label = None
        matched_polarity = None
        confidence = 0.0

        # èƒœè€…é€šåƒé€»è¾‘
        if best_pos_score > best_neg_score:
            if best_pos_score > threshold:
                matched_label = POS_LABELS_LIST[best_pos_idx]
                matched_polarity = "positive"
                confidence = best_pos_score
        else:
            if best_neg_score > threshold:
                matched_label = NEG_LABELS_LIST[best_neg_idx]
                matched_polarity = "negative"
                confidence = best_neg_score

        if matched_label:
            analyzed_results.append({
                "review_id": row_idx,
                "date": date_val,
                "rating": rating,
                "original_review": full_text,
                "sentence": sent,
                "polarity": matched_polarity,
                "label": matched_label,
                "evidence": sent,
                "confidence": round(confidence, 4)
            })

    # å…œåº•ï¼šå¦‚æœæ•´æ¡è¯„è®ºæ²¡æœ‰ä»»ä½•å¥å­åŒ¹é…åˆ°æ ‡ç­¾
    if not analyzed_results:
        fallback_label = "å·®è¯„å…¶ä»–" if review_polarity_base == "negative" else "å¥½è¯„å…¶ä»–"
        analyzed_results.append({
            "review_id": row_idx,
            "date": date_val,
            "rating": rating,
            "original_review": full_text,
            "sentence": "(æ— æ˜ç¡®ç‰¹å¾)",
            "polarity": review_polarity_base,
            "label": fallback_label,
            "evidence": full_text,
            "confidence": 0.0
        })

    return analyzed_results

# =========================
# 4. è¾…åŠ©å‡½æ•°
# =========================
def load_file(f):
    if f.name.lower().endswith(".csv"):
        try: return pd.read_csv(f, encoding="utf-8")
        except: return pd.read_csv(f, encoding="gbk")
    return pd.read_excel(f)

def parse_rating_strict(x):
    if pd.isna(x): return np.nan
    s = str(x)
    m = re.search(r"(\d+(\.\d+)?)", s)
    if m:
        val = int(round(float(m.group(1))))
        return max(1, min(5, val))
    return np.nan

# =========================
# 5. ä¸»ç¨‹åº UI
# =========================
st.title("ğŸ“Š AI å…¨ç»´è¯„è®ºåˆ†æçœ‹æ¿ (å¯è§†åŒ–å¢å¼ºç‰ˆ)")
st.markdown("""
**æ ¸å¿ƒåŠŸèƒ½ï¼š**
1. **è¯­ä¹‰æ‹†è§£**ï¼šè‡ªåŠ¨æ‹†åˆ†é•¿éš¾å¥ï¼Œç²¾å‡†å½’ç±»å¥½è¯„ä¸å·®è¯„ç‚¹ã€‚
2. **å¤šç»´å¯è§†åŒ–**ï¼šåŒ…å«æƒ…æ„Ÿåˆ†å¸ƒã€æ ‡ç­¾å¯¹æ¯”ã€æ˜Ÿçº§äº¤å‰åˆ†æåŠæ—¶é—´è¶‹åŠ¿ï¼ˆè‹¥æœ‰æ—¥æœŸï¼‰ã€‚
3. **å¼ºè¯æ®é“¾**ï¼šæ‰€æœ‰åˆ†æç»“æœå‡å…³è”åŸæ–‡å¥å­ã€‚
""")

with st.spinner("æ­£åœ¨åŠ è½½ AI ç¥ç»æ¨¡å‹..."):
    model = load_model()

uploaded = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (CSV/Excel)", type=["csv", "xlsx"])

if uploaded:
    with st.spinner('æ­£åœ¨è¿›è¡Œæ·±åº¦è¯­ä¹‰æ‹†è§£...'):
        df_raw = load_file(uploaded)
        
        # å­—æ®µæ™ºèƒ½è¯†åˆ«
        all_cols = df_raw.columns.tolist()
        # 1. æ˜Ÿçº§åˆ—
        rating_col = next((c for c in all_cols if "æ˜Ÿ" in str(c) or "rating" in str(c).lower()), all_cols[0])
        # 2. å†…å®¹åˆ—
        text_col = next((c for c in all_cols if "å†…å®¹" in str(c) or "review" in str(c).lower() or "text" in str(c).lower()), all_cols[1])
        # 3. æ—¥æœŸåˆ— (å¯é€‰)
        date_col = next((c for c in all_cols if "æ—¶é—´" in str(c) or "date" in str(c).lower() or "time" in str(c).lower()), None)
        
        # æ¸…æ´—
        df_raw["rating_clean"] = df_raw[rating_col].apply(parse_rating_strict)
        df_raw = df_raw.dropna(subset=["rating_clean"])
        df_raw["text_clean"] = df_raw[text_col].astype(str).fillna("")
        
        # å¤„ç†æ—¥æœŸ
        has_date = False
        if date_col:
            try:
                df_raw["date_clean"] = pd.to_datetime(df_raw[date_col], errors='coerce')
                if df_raw["date_clean"].notna().sum() > 0:
                    has_date = True
            except:
                pass
        
        if not has_date:
            df_raw["date_clean"] = None

        # æ ¸å¿ƒåˆ†æå¾ªç¯
        all_results = []
        progress_bar = st.progress(0)
        total = len(df_raw)
        
        for idx, row in df_raw.iterrows():
            if idx % 10 == 0: progress_bar.progress(idx / total)
            res = analyze_single_review(
                idx, 
                row["rating_clean"], 
                row["date_clean"], 
                row["text_clean"], 
                model
            )
            all_results.extend(res)
        
        progress_bar.empty()
        
        # è½¬æ¢ä¸ºæ‰“æ ‡å±‚çº§çš„ DataFrame
        detailed_df = pd.DataFrame(all_results)

    st.success(f"âœ… åˆ†æå®Œæˆï¼ä» {len(df_raw)} æ¡è¯„è®ºä¸­æ‹†è§£å‡º {len(detailed_df)} ä¸ªè¯­ä¹‰å•å…ƒã€‚")

    # ==========================================
    # ç»´åº¦ 1: å®è§‚æ¦‚è§ˆ (KPI & åŸºç¡€åˆ†å¸ƒ)
    # ==========================================
    st.markdown("---")
    st.header("1. å®è§‚æ•°æ®æ¦‚è§ˆ")
    
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("æ€»è¯„è®ºæ•°", len(df_raw))
    k1.metric("è¯­ä¹‰å•å…ƒæ•°", len(detailed_df), help="ä¸€æ¡è¯„è®ºå¯èƒ½æ‹†åˆ†æˆå¤šä¸ªè¯­ä¹‰ç‚¹")
    
    avg_score = df_raw['rating_clean'].mean()
    k2.metric("å¹³å‡è¯„åˆ†", f"{avg_score:.2f} â­")
    
    # å·®è¯„ç‡
    neg_reviews = len(df_raw[df_raw['rating_clean']<=3])
    k3.metric("å·®è¯„ç‡ (Review Level)", f"{(neg_reviews/len(df_raw)*100):.1f}%", delta_color="inverse")

    # ç»˜åˆ¶æ˜Ÿçº§åˆ†å¸ƒ (Bar Chart)
    st.subheader("è¯„åˆ†æ˜Ÿçº§åˆ†å¸ƒ")
    star_counts = df_raw['rating_clean'].value_counts().reindex([1,2,3,4,5], fill_value=0).sort_index()
    
    fig1, ax1 = plt.subplots(figsize=(10, 3))
    colors = ['#e74c3c', '#e67e22', '#f1c40f', '#3498db', '#2ecc71']
    bars = ax1.bar(star_counts.index, star_counts.values, color=colors, alpha=0.9)
    ax1.set_xticks([1,2,3,4,5])
    ax1.set_ylabel("æ•°é‡")
    ax1.grid(axis='y', linestyle='--', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                 f'{int(height)}', ha='center', va='bottom')
    
    st.pyplot(fig1)

    # ==========================================
    # ç»´åº¦ 2: æ ‡ç­¾æ·±åº¦åˆ†æ (å¥½è¯„ vs å·®è¯„)
    # ==========================================
    st.markdown("---")
    st.header("2. æ ‡ç­¾æ·±åº¦é€è§†")
    
    c1, c2 = st.columns(2)
    
    # --- å·¦ä¾§ï¼šæƒ…æ„Ÿå æ¯”é¥¼å›¾ ---
    with c1:
        st.subheader("è¯­ä¹‰æƒ…æ„Ÿå æ¯”")
        pol_counts = detailed_df['polarity'].value_counts()
        fig2, ax2 = plt.subplots(figsize=(6, 6))
        ax2.pie(pol_counts.values, labels=pol_counts.index, autopct='%1.1f%%', 
                colors=['#2ecc71', '#e74c3c'], startangle=140, explode=(0.05, 0))
        ax2.set_title("Sentiment Distribution")
        st.pyplot(fig2)
        
    # --- å³ä¾§ï¼šæ ‡ç­¾ Top æ¦œå• (å¯¹æ¯”å›¾) ---
    with c2:
        st.subheader("Top æ ‡ç­¾å¯¹æ¯”")
        # åˆ†åˆ«æå–å¥½è¯„å’Œå·®è¯„çš„å‰5å
        top_pos = detailed_df[detailed_df['polarity']=='positive']['label'].value_counts().head(5)
        top_neg = detailed_df[detailed_df['polarity']=='negative']['label'].value_counts().head(5)
        
        # åˆå¹¶ç»˜å›¾æ•°æ®
        labels = list(top_pos.index) + list(top_neg.index)
        counts = list(top_pos.values) + list(top_neg.values)
        colors = ['#2ecc71']*len(top_pos) + ['#e74c3c']*len(top_neg)
        
        fig3, ax3 = plt.subplots(figsize=(6, 6))
        y_pos = np.arange(len(labels))
        ax3.barh(y_pos, counts, color=colors)
        ax3.set_yticks(y_pos)
        ax3.set_yticklabels(labels)
        ax3.invert_yaxis() # æœ€å¤§çš„åœ¨ä¸Šé¢
        ax3.set_xlabel("æåŠæ¬¡æ•°")
        ax3.set_title("Top Positive vs Top Negative Labels")
        st.pyplot(fig3)

    # ==========================================
    # ç»´åº¦ 3: äº¤å‰åˆ†æ (æ˜Ÿçº§ x æƒ…æ„Ÿ)
    # ==========================================
    st.markdown("---")
    st.header("3. äº¤å‰åˆ†æï¼šæ˜Ÿçº§èƒŒåçš„çœŸå®å£°éŸ³")
    st.caption("æ£€æŸ¥ï¼šé«˜åˆ†è¯„è®ºé‡Œæ˜¯å¦è—ç€å·®è¯„æ ‡ç­¾ï¼Ÿä½åˆ†è¯„è®ºé‡Œæ˜¯å¦æœ‰å¥½è¯„ç‚¹ï¼Ÿ")
    
    # äº¤å‰è¡¨ï¼šæ˜Ÿçº§ vs æƒ…æ„Ÿ
    cross_tab = pd.crosstab(detailed_df['rating'], detailed_df['polarity'])
    
    fig4, ax4 = plt.subplots(figsize=(10, 5))
    cross_tab.plot(kind='bar', stacked=True, color=['#e74c3c', '#2ecc71'], ax=ax4)
    ax4.set_xlabel("æ˜Ÿçº§")
    ax4.set_ylabel("è¯­ä¹‰å•å…ƒæ•°é‡")
    ax4.set_title("æ˜Ÿçº§ä¸æƒ…æ„Ÿåˆ†å¸ƒå †å å›¾")
    ax4.legend(["Negative (å·®è¯„ç‚¹)", "Positive (å¥½è¯„ç‚¹)"], loc='upper left')
    plt.xticks(rotation=0)
    st.pyplot(fig4)
    
    #
