import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sentence_transformers import SentenceTransformer, util
from sklearn.feature_extraction.text import CountVectorizer
import torch
import re
import io

# =========================
# 0. é¡µé¢é…ç½®ä¸å®‰å…¨éªŒè¯
# =========================
st.set_page_config(page_title="AI è¯„è®ºåˆ†æ (è¯­ä¹‰ä¿®æ­£ç‰ˆ)", page_icon="ğŸ¯", layout="wide")

ACCESS_PASSWORD = "admin123" 

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state["password_input"] == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop() 

# =========================
# 1. æ ‡ç­¾åº“ä¸å…³é”®è¯è§„åˆ™ (æ·±åº¦ä¼˜åŒ–)
# =========================
# é€»è¾‘è¯´æ˜ï¼šå¦‚æœè¯„è®ºä¸­åŒ…å«åˆ—è¡¨é‡Œçš„è¯ï¼Œè¯¥æ ‡ç­¾çš„åˆ†æ•°ä¼šè·å¾—å·¨å¤§åŠ æˆã€‚

POS_LABELS_MAP = {
    # æé«˜ "åŠŸèƒ½æ€§" æ ‡ç­¾çš„ä¼˜å…ˆçº§ï¼Œé˜²æ­¢è¢« "èˆ’é€‚" æ©ç›–
    "æä¾›å‹ç¼©æ„Ÿ/æ”¯æ’‘åŠ›": ["compression", "pressure", "support", "tightness", "squeeze", "å‹åŠ›", "å‹ç¼©", "æ”¯æ’‘", "ç´§å®", "åŒ…è£¹"],
    "ç¼“è§£ç–¼ç—›/åŒ»ç–—æ•ˆæœ": ["pain", "relief", "arthritis", "ache", "soothing", "hurts", "ç–¼ç—›", "ç¼“è§£", "å…³èŠ‚ç‚", "æ­¢ç—›", "ç–—æ•ˆ"],
    "å¢åŠ æŠ“æ¡åŠ›/é˜²æ»‘": ["grip", "traction", "slip", "rubber", "æŠ“æ¡", "é˜²æ»‘", "æ‘©æ“¦", "ç¨³"],
    "ä¿æš–æ€§èƒ½å¥½": ["warm", "heat", "cold", "winter", "ä¿æš–", "çƒ­", "å†·", "æ¸©"],
    
    # é€šç”¨æ ‡ç­¾æ”¾åœ¨åé¢
    "é¢æ–™èˆ’é€‚/æŸ”è½¯": ["soft", "comfortable", "fabric", "cotton", "smooth", "cozy", "èˆ’é€‚", "è½¯", "æ£‰", "èˆ’æœ"],
    "åšå·¥è´¨é‡å¥½": ["quality", "well made", "sturdy", "stitch", "è´¨é‡", "åšå·¥", "ç¼çº¿", "è€ç”¨"],
    "å°ºç åˆèº«/èˆ’é€‚è´´åˆ": ["fit", "size", "snug", "perfect", "true to size", "åˆèº«", "åˆé€‚", "è´´åˆ"],
    "è€ç”¨æ€§å¼º": ["durable", "last", "wash", "wear", "è€ç”¨", "æ´—", "ç£¨æŸ"],
    "çµæ´»æ€§å¥½": ["dexterity", "flexible", "type", "write", "çµæ´»", "æ‰“å­—", "æ´»åŠ¨"],
}

NEG_LABELS_MAP = {
    # é’ˆå¯¹æ‚¨çš„æ¡ˆä¾‹1ï¼šå¢åŠ  "è¢–å£", "ä¼¸ä¸è¿›" ç­‰å…·ä½“åœºæ™¯è¯
    "å°ºç å¤ªå°/å¤ªç´§/ä¼¸ä¸è¿›å»": [
        "small", "tight", "cut off", "circulation", "cuff", "hand in", "wrist", "opening", 
        "restrict", "squeeze", "tiny", "child",
        "ç´§", "å°", "å‹’", "ä¼¸ä¸è¿›", "çª„", "è¢–å£", "ç©¿ä¸", "è¿›ä¸å»", "å¡ä½", "è¡€æ¶²å¾ªç¯"
    ],
    "å°ºç å¤ªå¤§/å¤ªæ¾": ["big", "loose", "huge", "large", "baggy", "fall off", "long", "æ¾", "å¤§", "é•¿", "æ‰"],
    "å¤ªæ»‘/æ²¡æœ‰æŠ“æ¡åŠ›": ["slippery", "slide", "no grip", "smooth", "plastic", "drop", "æ»‘", "æŠ“ä¸ä½", "æºœ"],
    "ç¼çº¿å¼€è£‚/ç ´æŸ": ["seam", "rip", "tear", "hole", "split", "fray", "thread", "unravel", "ç¼çº¿", "ç ´", "æ´", "å¼€è£‚", "çº¿å¤´", "è£‚"],
    "æ— æ•ˆ/æ²¡æœ‰ä½œç”¨": ["work", "effect", "useless", "help", "difference", "waste", "æ— æ•ˆ", "æ²¡ç”¨", "æ™ºå•†ç¨", "ä¸å€¼"],
    "è¿‡æ•/çš®ç–¹/å‘ç—’": ["rash", "itch", "allergy", "skin", "red", "bump", "ç—’", "è¿‡æ•", "çº¢è‚¿", "åˆºæŒ "],
    "é¢æ–™è´¨é‡å·®/å»‰ä»·": ["material", "thin", "cheap", "rough", "scratchy", "junk", "paper", "é¢æ–™", "è–„", "ç²—ç³™", "å»‰ä»·", "çƒ‚"],
    "æ•°é‡ä¸ç¬¦/å‘é”™è´§": ["count", "missing", "wrong", "received", "order", "æ•°é‡", "å°‘", "å‘é”™", "ç¼º"],
}

# æå–æ ‡ç­¾åˆ—è¡¨
POS_LABELS = list(POS_LABELS_MAP.keys())
NEG_LABELS = list(NEG_LABELS_MAP.keys())

# =========================
# 2. AI æ¨¡å‹åŠ è½½
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# =========================
# 3. æ ¸å¿ƒåŠŸèƒ½ï¼šæ··åˆæ‰“æ ‡ (å…³é”®è¯ > è¯­ä¹‰)
# =========================
def extract_dynamic_label(text, model, ngram_range=(2, 3)):
    try:
        is_chinese = bool(re.search(r'[\u4e00-\u9fff]', text))
        analyzer_type = 'char' if is_chinese else 'word'
        count = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer_type, stop_words='english').fit([text])
        candidates = count.get_feature_names_out()
        if len(candidates) == 0: return "å…¶ä»–æœªåˆ†ç±»"
        doc_embedding = model.encode([text])
        candidate_embeddings = model.encode(candidates)
        distances = util.cos_sim(doc_embedding, candidate_embeddings)
        keywords = [candidates[index] for index in distances.argsort()[0][-1:]]
        tag = keywords[0]
        return tag.replace(" ", "") if is_chinese else tag.title()
    except:
        return "å…¶ä»–(æ–‡æœ¬è¿‡çŸ­)"

def hybrid_classify(df, model, match_threshold=0.35):
    """
    é€»è¾‘å‡çº§ï¼š
    1. å…³é”®è¯å‘½ä¸­æ—¶ï¼Œç»™äºˆå·¨å¤§åŠ åˆ† (Bonus +1.5)ï¼Œç¡®ä¿è¦†ç›–è¯­ä¹‰ç›¸ä¼¼åº¦ã€‚
    2. å¦‚æœæœ‰ç‰¹å®šåŠŸèƒ½è¯ï¼ˆå¦‚â€œå‹åŠ›â€ï¼‰ï¼Œä¼˜å…ˆäºé€šç”¨è¯ï¼ˆå¦‚â€œèˆ’é€‚â€ï¼‰ã€‚
    """
    reviews = df['text'].tolist()
    
    review_embeddings = model.encode(reviews, convert_to_tensor=True)
    pos_embeddings = model.encode(POS_LABELS, convert_to_tensor=True)
    neg_embeddings = model.encode(NEG_LABELS, convert_to_tensor=True)
    
    pos_sims = util.cos_sim(review_embeddings, pos_embeddings)
    neg_sims = util.cos_sim(review_embeddings, neg_embeddings)
    
    final_labels = []
    sentiment_display = []
    is_new_label = []

    progress_bar = st.progress(0)
    total = len(df)
    
    for i in range(total):
        if i % 10 == 0: progress_bar.progress(i / total)

        rating = df.iloc[i]['rating']
        text = str(df.iloc[i]['text']).lower()
        
        # --- å…³é”®è¯å¼ºåŠ›åŠ æƒ ---
        
        # 1. å¤„ç†å·®è¯„
        current_neg_scores = neg_sims[i].clone()
        for idx, label in enumerate(NEG_LABELS):
            keywords = NEG_LABELS_MAP[label]
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
            if any(k in text for k in keywords):
                # +1.5 æ˜¯ä¸€ä¸ªå·¨å¤§çš„æƒé‡ï¼ŒåŸºæœ¬èƒ½ä¿è¯åªè¦æœ‰å…³é”®è¯ï¼Œå°±é€‰è¿™ä¸ªæ ‡ç­¾
                current_neg_scores[idx] += 1.5 

        # 2. å¤„ç†å¥½è¯„
        current_pos_scores = pos_sims[i].clone()
        for idx, label in enumerate(POS_LABELS):
            keywords = POS_LABELS_MAP[label]
            if any(k in text for k in keywords):
                # é’ˆå¯¹æ¡ˆä¾‹2ï¼šå¦‚æœæ˜¯"å‹ç¼©/å‹åŠ›"ç±»è¯ï¼ŒåŠ åˆ†æ›´é«˜ï¼Œå‹è¿‡"èˆ’é€‚"
                if "å‹ç¼©" in label or "compression" in label.lower():
                     current_pos_scores[idx] += 2.0 
                else:
                     current_pos_scores[idx] += 1.5

        # è·å–æœ€ä½³åŒ¹é…
        best_pos_idx = torch.argmax(current_pos_scores).item()
        best_pos_score = current_pos_scores[best_pos_idx].item()
        
        best_neg_idx = torch.argmax(current_neg_scores).item()
        best_neg_score = current_neg_scores[best_neg_idx].item()
        
        label = None
        s_display = "æœªçŸ¥"
        is_new = False
        
        # --- ä¸¥æ ¼çš„æƒ…æ„Ÿåˆ¤å®š (ä¿®å¤è¯„åˆ†é€»è¾‘) ---
        if rating <= 3:
            is_negative = True
        elif rating == 4:
            is_negative = best_neg_score > best_pos_score
        else:
            is_negative = False

        # --- æœ€ç»ˆå†³ç­– ---
        if is_negative:
            s_display = "å·®è¯„"
            # é˜ˆå€¼åˆ¤æ–­ï¼šå¦‚æœæœ‰å…³é”®è¯åŠ æˆï¼Œåˆ†æ•°è‚¯å®š > 1.0ï¼Œç›´æ¥é€šè¿‡
            if best_neg_score > match_threshold:
                label = NEG_LABELS[best_neg_idx]
            else:
                label = extract_dynamic_label(df.iloc[i]['text'], model)
                is_new = True
        else:
            s_display = "å¥½è¯„"
            if best_pos_score > match_threshold:
                label = POS_LABELS[best_pos_idx]
            else:
                label = extract_dynamic_label(df.iloc[i]['text'], model)
                is_new = True
        
        final_labels.append(label)
        sentiment_display.append(s_display)
        is_new_label.append(is_new)

    progress_bar.empty()
    return final_labels, sentiment_display, is_new_label

# =========================
# 4. è¾…åŠ©å·¥å…· (ä¸¥æ ¼è¯„åˆ†è§£æ)
# =========================
def load_file(f):
    if f.name.lower().endswith(".csv"):
        try: return pd.read_csv(f, encoding="utf-8")
        except: return pd.read_csv(f, encoding="gbk")
    return pd.read_excel(f)

def parse_rating_strict(x):
    if pd.isna(x): return np.nan
    s = str(x)
    m = re.search(r"(\d+(\.\d+)?)", s)
    if m:
        val = float(m.group(1))
        val_int = int(round(val)) # å››èˆäº”å…¥
        if val_int < 1: val_int = 1
        if val_int > 5: val_int = 5
        return val_int
    return np.nan

# =========================
# 5. ä¸»ç¨‹åº UI
# =========================
st.title("ğŸ¯ AI è¯„è®ºåˆ†æ (ç²¾å‡†è¯­ä¹‰ä¿®æ­£ç‰ˆ)")
st.markdown("""
**æœ¬æ¬¡ä¿®æ­£é‡ç‚¹ï¼š**
1. **è§£å†³â€œè¢–å£ä¼¸ä¸è¿›â€é—®é¢˜**ï¼šå¢åŠ äº† `è¢–å£`, `ä¼¸ä¸è¿›`, `cuff` ç­‰å¼ºè§„åˆ™è¯ï¼Œå¼ºåˆ¶è¯†åˆ«ä¸ºã€å°ºç å¤ªå°/å¤ªç´§ã€‘ã€‚
2. **è§£å†³â€œå‹åŠ›è¢«æ³›åŒ–â€é—®é¢˜**ï¼šæé«˜äº†åŠŸèƒ½æ€§è¯æ±‡ï¼ˆå¦‚ `å‹åŠ›`, `compression`ï¼‰çš„æƒé‡ï¼Œä¼˜å…ˆäºé€šç”¨çš„â€œèˆ’é€‚â€ã€‚
3. **è¯„åˆ†ç»Ÿè®¡ä¿®å¤**ï¼šå¼ºåˆ¶å°†æ‰€æœ‰è¯„åˆ†ï¼ˆå¦‚ 3.0ï¼‰è½¬ä¸ºæ•´æ•°ï¼Œå‡†ç¡®ç»Ÿè®¡å·®è¯„ã€‚
""")

with st.spinner("AI å¼•æ“åŠ è½½ä¸­..."):
    model = load_model()

uploaded = st.file_uploader("ä¸Šä¼ è¯„è®ºæ–‡ä»¶ (CSV/Excel)", type=["csv", "xlsx"])

if uploaded:
    with st.spinner('æ­£åœ¨è¿›è¡Œå…³é”®è¯å¢å¼ºåˆ†æ...'):
        df = load_file(uploaded)
        
        all_cols = df.columns.tolist()
        rating_col = next((c for c in all_cols if "æ˜Ÿ" in str(c) or "rating" in str(c).lower()), all_cols[0])
        text_col = next((c for c in all_cols if "å†…å®¹" in str(c) or "review" in str(c).lower() or "text" in str(c).lower()), all_cols[1])

        # ä¸¥æ ¼æ¸…æ´—
        df["rating_clean"] = df[rating_col].apply(parse_rating_strict)
        df = df.dropna(subset=["rating_clean"])
        df["rating_clean"] = df["rating_clean"].astype(int)
        df["text"] = df[text_col].astype(str).fillna("")
        df["rating"] = df["rating_clean"]
        
        # æ ¸å¿ƒè¿ç®—
        labels, sentiments, is_new = hybrid_classify(df, model)
        df["æ ‡ç­¾"] = labels
        df["æƒ…æ„Ÿåˆ†ç±»"] = sentiments
        df["æ˜¯å¦æ–°æ ‡ç­¾"] = is_new
        
    st.success("âœ… åˆ†æå®Œæˆï¼")

    # =========================
    # A: å®è§‚æ¦‚è§ˆ
    # =========================
    st.markdown("---")
    st.header("1. å®è§‚æ¦‚è§ˆ")
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("è¯„è®ºæ€»æ•°", len(df))
    avg_score = df['rating'].mean()
    k2.metric("å¹³å‡è¯„åˆ†", f"{avg_score:.2f} â­")
    
    neg_count = len(df[df['rating'] <= 3])
    neg_rate = (neg_count / len(df) * 100) if len(df) > 0 else 0
    k3.metric("å·®è¯„å æ¯” (<=3æ˜Ÿ)", f"{neg_rate:.1f}%", delta_color="inverse")
    k4.metric("æ–°æ ‡ç­¾æŒ–æ˜", sum(is_new))
    
    # è¯„åˆ†åˆ†å¸ƒ
    counts = df['rating'].value_counts().reindex([1,2,3,4,5], fill_value=0).reset_index()
    counts.columns = ["æ˜Ÿçº§", "æ•°é‡"]
    counts["æ˜Ÿçº§"] = counts["æ˜Ÿçº§"].astype(str) + "æ˜Ÿ"
    fig_bar = px.bar(counts, x="æ˜Ÿçº§", y="æ•°é‡", text="æ•°é‡", color="æ•°é‡", color_continuous_scale="Blues")
    st.plotly_chart(fig_bar, use_container_width=True)

    # =========================
    # B: æ·±åº¦åˆ†æ
    # =========================
    st.markdown("---")
    st.header("2. æ ‡ç­¾æ·±åº¦åˆ†æ")
    c1, c2 = st.columns(2)
    with c1:
        s_counts = df["æƒ…æ„Ÿåˆ†ç±»"].value_counts().reset_index()
        s_counts.columns = ["æƒ…æ„Ÿ", "æ•°é‡"]
        fig_pie = px.pie(s_counts, values="æ•°é‡", names="æƒ…æ„Ÿ", hole=0.4, 
                         color="æƒ…æ„Ÿ", color_discrete_map={"å¥½è¯„":"#2ecc71", "å·®è¯„":"#e74c3c"})
        st.plotly_chart(fig_pie, use_container_width=True)
    with c2:
        viz_df = df.copy()
        tc = viz_df["æ ‡ç­¾"].value_counts()
        viz_df["æ ‡ç­¾å±•ç¤º"] = viz_df["æ ‡ç­¾"].apply(lambda x: x if tc[x] > 0 else "å…¶ä»–")
        sun_df = viz_df.groupby(["æƒ…æ„Ÿåˆ†ç±»", "æ ‡ç­¾å±•ç¤º"]).size().reset_index(name="æ•°é‡")
        fig_sun = px.sunburst(sun_df, path=['æƒ…æ„Ÿåˆ†ç±»', 'æ ‡ç­¾å±•ç¤º'], values='æ•°é‡',
                              color='æƒ…æ„Ÿåˆ†ç±»', color_discrete_map={"å¥½è¯„":"#2ecc71", "å·®è¯„":"#e74c3c"})
        st.plotly_chart(fig_sun, use_container_width=True)

    # =========================
    # C: éªŒè¯åŒº (æŸ¥æ‰¾ç‰¹å®šè¯„è®º)
    # =========================
    st.markdown("---")
    st.header("3. ç»“æœéªŒè¯")
    st.caption("æ£€æŸ¥ç‰¹å®šæ ‡ç­¾ä¸‹çš„è¯„è®ºæ˜¯å¦å‡†ç¡®")
    
    col_v1, col_v2 = st.columns(2)
    with col_v1:
        # å·®è¯„éªŒè¯
        neg_issues = df[df["æƒ…æ„Ÿåˆ†ç±»"] == "å·®è¯„"]["æ ‡ç­¾"].unique().tolist()
        if neg_issues:
            sel_neg = st.selectbox("æŸ¥çœ‹å·®è¯„æ ‡ç­¾:", neg_issues)
            reviews_n = df[df["æ ‡ç­¾"] == sel_neg]["text"].head(3)
            for r in reviews_n: st.error(r)
        else:
            st.info("æ— å·®è¯„")
            
    with col_v2:
        # å¥½è¯„éªŒè¯
        pos_issues = df[df["æƒ…æ„Ÿåˆ†ç±»"] == "å¥½è¯„"]["æ ‡ç­¾"].unique().tolist()
        if pos_issues:
            sel_pos = st.selectbox("æŸ¥çœ‹å¥½è¯„æ ‡ç­¾:", pos_issues)
            reviews_p = df[df["æ ‡ç­¾"] == sel_pos]["text"].head(3)
            for r in reviews_p: st.success(r)
        else:
            st.info("æ— å¥½è¯„")

    # =========================
    # ä¸‹è½½
    # =========================
    st.markdown("---")
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Result')
    st.download_button("â¬‡ï¸ ä¸‹è½½ Excel ç»“æœ", buffer.getvalue(), "fixed_analysis.xlsx", "application/vnd.ms-excel")
