import streamlit as st
import pandas as pd
import numpy as np
import altair as alt  # æ ¸å¿ƒå˜åŠ¨ï¼šä½¿ç”¨ Altair æ›¿ä»£ Matplotlib
from sentence_transformers import SentenceTransformer, util
import torch
import re
import io

# =========================
# 0. é¡µé¢é…ç½®
# =========================
st.set_page_config(
    page_title="AI è¯­ä¹‰åˆ†æçœ‹æ¿ (Altairç‰ˆ)",
    page_icon="ğŸ“Š",
    layout="wide"
)

ACCESS_PASSWORD = "admin123" 

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state["password_input"] == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop() 

# =========================
# 1. æ ‡ç­¾åº“å®šä¹‰ (å›ºå®šé›†åˆ)
# =========================
POS_LABELS_LIST = [
    "é¢æ–™èˆ’é€‚", "è´¨é‡å¾ˆå¥½", "æœ‰åŠ©äºé”»ç‚¼", "æœ‰åŠ©äºç¼“è§£ç–¼ç—›", "ä¿æš–", "èˆ’é€‚è´´åˆ", 
    "æœ‰å‹ç¼©æ„Ÿ", "æŠ“æ¡å¼æœ‰æ•ˆ", "åˆèº«", "æœ‰åŠ©äºå…³èŠ‚ç‚/æ‰³æœºæŒ‡", "å¢åŠ æ‰‹æŒ‡çµæ´»", 
    "ä¿ƒè¿›è¡€æ¶²å¾ªç¯", "è€ç”¨", "ç¼“è§£ä¸é€‚", "è½»ç›ˆ", "è¦†ç›–æ•´ä¸ªæ‰‹æŒ‡", "æœ‰åŠ©äºé˜²æ­¢å—ä¼¤"
]

NEG_LABELS_LIST = [
    "æ— æ•ˆ/æ²¡æœ‰ä½œç”¨", "ç¼çº¿å¼€è£‚/ç ´æŸ", "æ”¶åˆ°äºŒæ‰‹/è„æ±¡", "é¢æ–™è´¨é‡å·®/å»‰ä»·", 
    "å°ºç å¤ªå°/å¤ªç´§", "å°ºç å¤ªå¤§/å¤ªæ¾", "æ¥ç¼å¤„ç£¨æ‰‹/ä¸é€‚", "ä¸è€ç”¨/ä¸€æ¬¡æ€§", 
    "è¿‡æ•/çš®ç–¹/å‘ç—’", "å¤ªæ»‘/æ²¡æœ‰æŠ“æ¡åŠ›", "æ•°é‡ä¸ç¬¦/å‘é”™è´§", "å¯¼è‡´è¡€æ¶²å¾ªç¯å—é˜»"
]

# =========================
# 2. AI æ¨¡å‹åŠ è½½
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# =========================
# 3. æ ¸å¿ƒ NLP å¼•æ“ (ä¿æŒåŸé€»è¾‘ä¸å˜)
# =========================
def split_into_sentences(text):
    """æ‹†å¥é€»è¾‘"""
    if not isinstance(text, str): return []
    sentences = re.split(r'[.!?;ã€‚ï¼ï¼Ÿï¼›\n]+', text)
    return [s.strip() for s in sentences if len(s.strip()) > 1]

def analyze_single_review(row_idx, rating, date_val, full_text, model, threshold=0.40):
    """å•æ¡è¯„è®ºæ·±åº¦æ‹†è§£"""
    sentences = split_into_sentences(full_text)
    analyzed_results = []
    
    pos_embeddings = model.encode(POS_LABELS_LIST, convert_to_tensor=True)
    neg_embeddings = model.encode(NEG_LABELS_LIST, convert_to_tensor=True)
    
    # åŸºäºæ˜Ÿçº§çš„åŸºå‡†æƒ…æ„Ÿ
    review_polarity_base = "negative" if rating <= 3 else "positive"

    # æ— æ³•æ‹†å¥æˆ–ç©ºè¯„è®ºå¤„ç†
    if not sentences:
        fallback_label = "å·®è¯„å…¶ä»–" if review_polarity_base == "negative" else "å¥½è¯„å…¶ä»–"
        return [{
            "review_id": row_idx,
            "date": date_val,
            "rating": rating,
            "original_review": full_text,
            "sentence": full_text[:50], 
            "polarity": review_polarity_base,
            "label": fallback_label,
            "evidence": full_text,
            "confidence": 0.5
        }]

    for sent in sentences:
        sent_embedding = model.encode(sent, convert_to_tensor=True)
        pos_scores = util.cos_sim(sent_embedding, pos_embeddings)[0]
        neg_scores = util.cos_sim(sent_embedding, neg_embeddings)[0]

        best_pos_score = torch.max(pos_scores).item()
        best_pos_idx = torch.argmax(pos_scores).item()
        best_neg_score = torch.max(neg_scores).item()
        best_neg_idx = torch.argmax(neg_scores).item()

        matched_label = None
        matched_polarity = None
        confidence = 0.0

        # èƒœè€…é€šåƒé€»è¾‘
        if best_pos_score > best_neg_score:
            if best_pos_score > threshold:
                matched_label = POS_LABELS_LIST[best_pos_idx]
                matched_polarity = "positive"
                confidence = best_pos_score
        else:
            if best_neg_score > threshold:
                matched_label = NEG_LABELS_LIST[best_neg_idx]
                matched_polarity = "negative"
                confidence = best_neg_score

        if matched_label:
            analyzed_results.append({
                "review_id": row_idx,
                "date": date_val,
                "rating": rating,
                "original_review": full_text,
                "sentence": sent,
                "polarity": matched_polarity,
                "label": matched_label,
                "evidence": sent,
                "confidence": round(confidence, 4)
            })

    # å…œåº•
    if not analyzed_results:
        fallback_label = "å·®è¯„å…¶ä»–" if review_polarity_base == "negative" else "å¥½è¯„å…¶ä»–"
        analyzed_results.append({
            "review_id": row_idx,
            "date": date_val,
            "rating": rating,
            "original_review": full_text,
            "sentence": "(æ— æ˜ç¡®ç‰¹å¾)",
            "polarity": review_polarity_base,
            "label": fallback_label,
            "evidence": full_text,
            "confidence": 0.0
        })

    return analyzed_results

# =========================
# 4. è¾…åŠ©å‡½æ•°
# =========================
def load_file(f):
    if f.name.lower().endswith(".csv"):
        try: return pd.read_csv(f, encoding="utf-8")
        except: return pd.read_csv(f, encoding="gbk")
    return pd.read_excel(f)

def parse_rating_strict(x):
    if pd.isna(x): return np.nan
    s = str(x)
    m = re.search(r"(\d+(\.\d+)?)", s)
    if m:
        val = int(round(float(m.group(1))))
        return max(1, min(5, val))
    return np.nan

# =========================
# 5. ä¸»ç¨‹åº UI
# =========================
st.title("ğŸ“Š AI å…¨ç»´è¯„è®ºåˆ†æçœ‹æ¿ (æ— ä¹±ç ç‰ˆ)")
st.markdown("""
**æœ¬æ¬¡æ›´æ–°ï¼š**
1. **å¯è§†åŒ–é‡æ„**ï¼šå¼ƒç”¨ Matplotlibï¼Œæ”¹ç”¨ **Altair**ã€‚å›¾è¡¨æ–‡å­—ç”±æµè§ˆå™¨æ¸²æŸ“ï¼Œ**å½»åº•è§£å†³ä¸­æ–‡ä¹±ç /æ–¹æ¡†é—®é¢˜**ã€‚
2. **äº¤äº’å¢å¼º**ï¼šæ‰€æœ‰å›¾è¡¨æ”¯æŒé¼ æ ‡æ‚¬åœæŸ¥çœ‹è¯¦ç»†æ•°æ®ã€‚
3. **è´è¶å›¾**ï¼šå¥½è¯„å‘å³ï¼Œå·®è¯„å‘å·¦ï¼Œå¯¹æ¯”æ›´ç›´è§‚ã€‚
""")

with st.spinner("AI ç¥ç»æ¨¡å‹åŠ è½½ä¸­..."):
    model = load_model()

uploaded = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (CSV/Excel)", type=["csv", "xlsx"])

if uploaded:
    with st.spinner('æ­£åœ¨è¿›è¡Œæ·±åº¦è¯­ä¹‰æ‹†è§£...'):
        df_raw = load_file(uploaded)
        
        # å­—æ®µæ™ºèƒ½è¯†åˆ«
        all_cols = df_raw.columns.tolist()
        rating_col = next((c for c in all_cols if "æ˜Ÿ" in str(c) or "rating" in str(c).lower()), all_cols[0])
        text_col = next((c for c in all_cols if "å†…å®¹" in str(c) or "review" in str(c).lower() or "text" in str(c).lower()), all_cols[1])
        date_col = next((c for c in all_cols if "æ—¶é—´" in str(c) or "date" in str(c).lower() or "time" in str(c).lower()), None)
        
        # æ¸…æ´—
        df_raw["rating_clean"] = df_raw[rating_col].apply(parse_rating_strict)
        df_raw = df_raw.dropna(subset=["rating_clean"])
        df_raw["text_clean"] = df_raw[text_col].astype(str).fillna("")
        
        # å¤„ç†æ—¥æœŸ
        has_date = False
        if date_col:
            try:
                df_raw["date_clean"] = pd.to_datetime(df_raw[date_col], errors='coerce')
                if df_raw["date_clean"].notna().sum() > 0:
                    has_date = True
            except:
                pass
        if not has_date:
            df_raw["date_clean"] = None

        # æ ¸å¿ƒåˆ†æ
        all_results = []
        progress_bar = st.progress(0)
        total = len(df_raw)
        
        for idx, row in df_raw.iterrows():
            if idx % 10 == 0: progress_bar.progress(idx / total)
            res = analyze_single_review(idx, row["rating_clean"], row["date_clean"], row["text_clean"], model)
            all_results.extend(res)
        
        progress_bar.empty()
        detailed_df = pd.DataFrame(all_results)

    st.success(f"âœ… åˆ†æå®Œæˆï¼æ‹†è§£å‡º {len(detailed_df)} ä¸ªè¯­ä¹‰å•å…ƒã€‚")

    # ==========================================
    # ç»´åº¦ 1: å®è§‚æ¦‚è§ˆ
    # ==========================================
    st.markdown("---")
    st.header("1. å®è§‚æ•°æ®æ¦‚è§ˆ")
    
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("æ€»è¯„è®ºæ•°", len(df_raw))
    avg_score = df_raw['rating_clean'].mean()
    k2.metric("å¹³å‡è¯„åˆ†", f"{avg_score:.2f} â­")
    
    neg_reviews = len(df_raw[df_raw['rating_clean']<=3])
    k3.metric("å·®è¯„ç‡", f"{(neg_reviews/len(df_raw)*100):.1f}%", delta_color="inverse")
    
    # Altair: æ˜Ÿçº§åˆ†å¸ƒæŸ±çŠ¶å›¾
    st.subheader("è¯„åˆ†åˆ†å¸ƒ")
    star_counts = df_raw['rating_clean'].value_counts().reset_index()
    star_counts.columns = ['Rating', 'Count']
    
    chart_stars = alt.Chart(star_counts).mark_bar().encode(
        x=alt.X('Rating:O', title='æ˜Ÿçº§'), # O for Ordinal
        y=alt.Y('Count:Q', title='è¯„è®ºæ•°'),
        color=alt.Color('Rating:O', scale=alt.Scale(scheme='blues'), legend=None),
        tooltip=['Rating', 'Count']
    ).properties(height=300)
    
    st.altair_chart(chart_stars, use_container_width=True)

    # ==========================================
    # ç»´åº¦ 2: è´è¶å›¾ (å¥½è¯„ vs å·®è¯„)
    # ==========================================
    st.markdown("---")
    st.header("2. å¸‚åœºå£ç¢‘å¯¹æ¯” (è´è¶å›¾)")
    st.caption("ğŸ‘ˆ å·¦ä¾§çº¢è‰²ä¸ºå·®è¯„ç—›ç‚¹ | å³ä¾§ç»¿è‰²ä¸ºå¥½è¯„å–ç‚¹ ğŸ‘‰")
    
    # æ•°æ®å‡†å¤‡
    label_counts = detailed_df.groupby(['label', 'polarity']).size().reset_index(name='count')
    # è®©å·®è¯„æ•°é‡å˜æˆè´Ÿæ•°ï¼Œä»¥ä¾¿åœ¨å›¾ä¸­å‘å·¦å»¶ä¼¸
    label_counts['display_count'] = label_counts.apply(lambda x: -x['count'] if x['polarity'] == 'negative' else x['count'], axis=1)
    # æ’åºï¼šæŒ‰ç»å¯¹å€¼æ•°é‡æ’åº
    label_counts['abs_count'] = label_counts['count'].abs()
    
    # è¿‡æ»¤æ‰æ•°é‡å¤ªå°‘çš„æ ‡ç­¾ï¼Œä¿æŒå›¾è¡¨æ•´æ´
    top_labels = label_counts.sort_values('abs_count', ascending=False).head(20)

    # Altair: è´è¶å›¾
    butterfly_chart = alt.Chart(top_labels).mark_bar().encode(
        x=alt.X('display_count:Q', title='æåŠæ¬¡æ•° (è´Ÿæ•°ä»£è¡¨å·®è¯„)', axis=alt.Axis(format='d')),
        y=alt.Y('label:N', title=None, sort=alt.EncodingSortField(field="abs_count", order="descending")),
        color=alt.Color('polarity:N', scale=alt.Scale(domain=['negative', 'positive'], range=['#e74c3c', '#2ecc71']), legend=alt.Legend(title="æƒ…æ„Ÿå€¾å‘")),
        tooltip=[alt.Tooltip('label', title='æ ‡ç­¾'), alt.Tooltip('count', title='æåŠæ¬¡æ•°'), alt.Tooltip('polarity', title='æƒ…æ„Ÿ')]
    ).properties(height=500)

    # æ·»åŠ ä¸­é—´çš„æ–‡å­—æ ‡ç­¾ (å¯é€‰ï¼Œç®€å•èµ·è§ç›´æ¥å±•ç¤ºå›¾)
    st.altair_chart(butterfly_chart, use_container_width=True)

    # ==========================================
    # ç»´åº¦ 3: äº¤å‰åˆ†æ (æ˜Ÿçº§å †å å›¾)
    # ==========================================
    st.markdown("---")
    st.header("3. æ˜Ÿçº§ä¸è¯­ä¹‰æˆåˆ†åˆ†æ")
    st.caption("æŸ¥çœ‹æ¯ä¸ªæ˜Ÿçº§ä¸­ï¼ŒåŒ…å«äº†å¤šå°‘å¥½è¯„è¯­ä¹‰å’Œå·®è¯„è¯­ä¹‰")
    
    # æ•°æ®èšåˆ
    stack_data = detailed_df.groupby(['rating', 'polarity']).size().reset_index(name='count')
    
    stack_chart = alt.Chart(stack_data).mark_bar().encode(
        x=alt.X('rating:O', title='æ˜Ÿçº§'),
        y=alt.Y('count:Q', title='è¯­ä¹‰å•å…ƒæ•°é‡'),
        color=alt.Color('polarity:N', scale=alt.Scale(domain=['negative', 'positive'], range=['#e74c3c', '#2ecc71'])),
        tooltip=['rating', 'polarity', 'count']
    ).properties(height=400)
    
    st.altair_chart(stack_chart, use_container_width=True)

    # ==========================================
    # ç»´åº¦ 4: è¯æ®å›æº¯
    # ==========================================
    st.markdown("---")
    st.header("4. è¯æ®å›æº¯ (Traceability)")
    
    search_label = st.selectbox("ğŸ” é€‰æ‹©æ ‡ç­¾æŸ¥çœ‹åŸæ–‡è¯æ®:", detailed_df['label'].unique())
    
    subset = detailed_df[detailed_df['label'] == search_label]
    st.write(f"æ ‡ç­¾ **ã€{search_label}ã€‘** å…±å‡ºç° {len(subset)} æ¬¡ï¼š")
    
    for i, row in subset.head(5).iterrows():
        with st.expander(f"{row['rating']}æ˜Ÿ | è¯­ä¹‰åŒ¹é…åº¦: {row['confidence']}"):
            # é«˜äº®è¯æ®
            st.markdown(f"**æ‹†è§£è¯­ä¹‰:** :red[{row['evidence']}]")
            st.caption(f"**å®Œæ•´åŸæ–‡:** {row['original_review']}")

    # ==========================================
    # ä¸‹è½½æ•°æ®
    # ==========================================
    st.markdown("---")
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        detailed_df.to_excel(writer, index=False, sheet_name='Detailed_Labels')
        df_raw.to_excel(writer, index=False, sheet_name='Raw_Data')
        
    st.download_button(
        label="â¬‡ï¸ ä¸‹è½½å®Œæ•´åˆ†ææŠ¥è¡¨ (Excel)",
        data=buffer.getvalue(),
        file_name="altair_analysis_report.xlsx",
        mime="application/vnd.ms-excel"
    )
