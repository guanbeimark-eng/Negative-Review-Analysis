import streamlit as st
import pandas as pd
import json
import uuid
import io

# ==========================================
# 0. åŸºç¡€é…ç½®ä¸å®‰å…¨ç™»å½•
# ==========================================
st.set_page_config(
    page_title="LLM è¯„è®ºæ™ºèƒ½æ¸…æ´—å±‹", 
    page_icon="ğŸ§¹", 
    layout="wide"
)

# --- ç®€å•çš„å¯†ç ä¿æŠ¤ (é€‚åˆå…¬å¼€éƒ¨ç½²) ---
# ä¿®æ”¹è¿™é‡Œçš„å¯†ç 
ACCESS_PASSWORD = "admin123" 

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    """éªŒè¯å¯†ç å›è°ƒ"""
    if st.session_state["password_input"] == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯ï¼Œè¯·é‡è¯•")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.markdown("è¯¥å·¥å…·å·²éƒ¨ç½²åœ¨äº‘ç«¯ï¼Œè¯·è¾“å…¥è®¿é—®å¯†ç ä»¥ç»§ç»­ã€‚")
    st.text_input("è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

# ==========================================
# 1. å…¨å±€ Session State åˆå§‹åŒ–
# ==========================================
if 'main_df' not in st.session_state:
    st.session_state.main_df = None       # åŸå§‹æ•°æ®
if 'normalized_df' not in st.session_state:
    st.session_state.normalized_df = None # æ ‡å‡†åŒ–åçš„ç²¾ç®€æ•°æ®
if 'tag_config' not in st.session_state:
    st.session_state.tag_config = {"pos": [], "neg": [], "all": []} # æ ‡ç­¾åº“é…ç½®
if 'generated_batches' not in st.session_state:
    st.session_state.generated_batches = [] # ç”Ÿæˆçš„ Prompt æ‰¹æ¬¡

# ==========================================
# 2. å·¥å…·å‡½æ•°
# ==========================================
def load_file(uploaded_file):
    """å…¼å®¹ CSV å’Œ Excel çš„åŠ è½½å‡½æ•°"""
    try:
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(uploaded_file)
        else:
            return pd.read_excel(uploaded_file)
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None

def safe_json_parse(json_str):
    """æ¸…æ´—å¹¶è§£æ LLM è¿”å›çš„ JSON"""
    if not json_str: return None
    try:
        # 1. ç§»é™¤ Markdown ä»£ç å—æ ‡è®°
        clean_str = json_str.replace("```json", "").replace("```", "").strip()
        # 2. å°è¯•è§£æ
        return json.loads(clean_str)
    except json.JSONDecodeError:
        st.error("JSON è§£æå¤±è´¥ã€‚è¯·æ£€æŸ¥æ¨¡å‹è¿”å›çš„å†…å®¹æ˜¯å¦åŒ…å«é JSON æ–‡å­—ã€‚")
        return None

# ==========================================
# 3. é¡µé¢ä¸»ä½“å¸ƒå±€
# ==========================================
st.title("ğŸš€ LLM è¯„è®ºæ•°æ®æ¸…æ´—æµæ°´çº¿")
st.markdown("### æµç¨‹ï¼šå¯¼å…¥æ•°æ® â†’ é…ç½®æ ‡ç­¾ â†’ ç”ŸæˆæŒ‡ä»¤ â†’ å›å¡«ç»“æœ")

# åˆ›å»ºå››ä¸ªåŠŸèƒ½æ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“‚ 1. æ•°æ®å¯¼å…¥", 
    "ğŸ·ï¸ 2. è¯„ä»·åº“é…ç½®", 
    "ğŸ¤– 3. Prompt ç”Ÿæˆå™¨", 
    "ğŸ“¥ 4. ç»“æœå›å¡«ä¸å¯¼å‡º"
])

# ------------------------------------------
# Tab 1: æ•°æ®å¯¼å…¥ä¸æ¸…æ´—
# ------------------------------------------
with tab1:
    st.header("Step 1: ä¸Šä¼ åŸå§‹è¯„è®ºè¡¨")
    uploaded_file = st.file_uploader("æ”¯æŒ CSV / Excel", type=['csv', 'xlsx', 'xls'])

    if uploaded_file:
        df = load_file(uploaded_file)
        if df is not None:
            st.session_state.main_df = df
            st.success(f"æˆåŠŸåŠ è½½ {len(df)} è¡Œæ•°æ®")
            
            with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®é¢„è§ˆ", expanded=True):
                st.dataframe(df.head(3))

            st.markdown("---")
            st.subheader("ğŸ”§ å­—æ®µæ˜ å°„ (å‘Šè¯‰ç¨‹åºå“ªåˆ—æ˜¯å“ªåˆ—)")
            
            all_cols = df.columns.tolist()
            c1, c2, c3, c4 = st.columns(4)
            
            # æ™ºèƒ½é¢„é€‰åˆ—å
            idx_rating = all_cols.index('rating') if 'rating' in all_cols else 0
            idx_content = all_cols.index('content') if 'content' in all_cols else 0
            
            with c1:
                col_rating = st.selectbox("æ˜Ÿçº§ (Rating) *å¿…é€‰", all_cols, index=idx_rating)
            with c2:
                col_title = st.selectbox("æ ‡é¢˜ (Title)", ["--å¿½ç•¥--"] + all_cols)
            with c3:
                col_content = st.selectbox("å†…å®¹ (Content) *å¿…é€‰", all_cols, index=idx_content)
            with c4:
                col_trans = st.selectbox("ç¿»è¯‘ (Translation)", ["--å¿½ç•¥--"] + all_cols)

            col_id_opt = st.selectbox("å”¯ä¸€ID (Review ID)", ["-- è‡ªåŠ¨ç”Ÿæˆ UUID (æ¨è) --"] + all_cols)

            if st.button("å¼€å§‹æ ‡å‡†åŒ–å¤„ç†", type="primary"):
                # 1. å¤åˆ¶å‰¯æœ¬
                norm_df = df.copy()
                
                # 2. å¤„ç† ID
                if col_id_opt.startswith("--"):
                    # ç”Ÿæˆ8ä½UUID
                    norm_df['sys_uuid'] = [str(uuid.uuid4())[:8] for _ in range(len(norm_df))]
                    # åŒæ—¶å›å†™åˆ°ä¸»è¡¨ï¼Œæ–¹ä¾¿åç»­åˆå¹¶
                    st.session_state.main_df['sys_uuid'] = norm_df['sys_uuid'] 
                    target_id_col = 'sys_uuid'
                else:
                    # å¼ºåˆ¶è½¬ä¸ºå­—ç¬¦ä¸²é˜²æ­¢åŒ¹é…é”™è¯¯
                    norm_df[col_id_opt] = norm_df[col_id_opt].astype(str)
                    target_id_col = col_id_opt

                # 3. å¤„ç†æ˜Ÿçº§ (æ¸…æ´—éæ•°å­—å­—ç¬¦)
                norm_df['rating_std'] = pd.to_numeric(norm_df[col_rating], errors='coerce').fillna(0).astype(int)

                # 4. æ‹¼æ¥æ–‡æœ¬
                def combine_text(row):
                    parts = []
                    if col_title != "--å¿½ç•¥--" and pd.notna(row[col_title]):
                        parts.append(f"Title: {row[col_title]}")
                    if pd.notna(row[col_content]):
                        parts.append(f"Content: {row[col_content]}")
                    if col_trans != "--å¿½ç•¥--" and pd.notna(row[col_trans]):
                        parts.append(f"Trans: {row[col_trans]}")
                    return "\n".join(parts)

                norm_df['text_combined'] = norm_df.apply(combine_text, axis=1)

                # 5. ä¿å­˜æ ‡å‡†åŒ–ç»“æœåˆ° Session
                st.session_state.normalized_df = norm_df[[target_id_col, 'rating_std', 'text_combined']].rename(
                    columns={target_id_col: 'id', 'rating_std': 'rating', 'text_combined': 'text'}
                )
                
                st.success("âœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆï¼å·²ç”Ÿæˆæ ‡å‡†ä¸­é—´è¡¨ã€‚è¯·å‰å¾€ Step 2ã€‚")
                st.dataframe(st.session_state.normalized_df.head())

# ------------------------------------------
# Tab 2: è¯„ä»·åº“é…ç½®
# ------------------------------------------
with tab2:
    st.header("Step 2: å¯¼å…¥æ ‡ç­¾åº“è§„åˆ™")
    st.info("ä¸Šä¼ è¡¨å¤´è¯´æ˜ï¼šå¿…é¡»åŒ…å« `label` (æ ‡ç­¾å) å’Œ `polarity` (positive/negative) ä¸¤åˆ—")
    
    tag_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾åº“ Excel/CSV", type=['csv', 'xlsx'])
    
    if tag_file:
        tag_df = load_file(tag_file)
        if tag_df is not None:
            c1, c2 = st.columns(2)
            lbl_col = c1.selectbox("é€‰æ‹©æ ‡ç­¾åˆ—", tag_df.columns)
            pol_col = c2.selectbox("é€‰æ‹©ææ€§åˆ—", tag_df.columns)
            
            if st.button("è§£ææ ‡ç­¾åº“"):
                # ç»Ÿä¸€è½¬å°å†™è¿›è¡ŒåŒ¹é…
                tag_df['pol_lower'] = tag_df[pol_col].astype(str).str.lower()
                
                # æå–å¥½è¯„/å·®è¯„
                pos_list = tag_df[tag_df['pol_lower'].str.contains('pos|good|å¥½|æ­£')][lbl_col].dropna().unique().tolist()
                neg_list = tag_df[tag_df['pol_lower'].str.contains('neg|bad|å·®|è´Ÿ')][lbl_col].dropna().unique().tolist()
                
                st.session_state.tag_config = {
                    "pos": pos_list,
                    "neg": neg_list,
                    "all": list(set(pos_list + neg_list))
                }
                
                st.success("âœ… æ ‡ç­¾åº“åŠ è½½æˆåŠŸï¼")
                col_res1, col_res2 = st.columns(2)
                col_res1.metric("å¥½è¯„æ ‡ç­¾æ•°", len(pos_list))
                col_res2.metric("å·®è¯„æ ‡ç­¾æ•°", len(neg_list))
                
                with st.expander("æŸ¥çœ‹è§£æåçš„åˆ—è¡¨"):
                    st.write("**Positive Tags:**", pos_list)
                    st.write("**Negative Tags:**", neg_list)

# ------------------------------------------
# Tab 3: Prompt ç”Ÿæˆå™¨
# ------------------------------------------
with tab3:
    st.header("Step 3: ç”Ÿæˆåˆ†æ‰¹æŒ‡ä»¤")
    
    if st.session_state.normalized_df is None:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ Step 1 å®Œæˆæ•°æ®æ ‡å‡†åŒ–")
        st.stop()
    if not st.session_state.tag_config['all']:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ Step 2 åŠ è½½æ ‡ç­¾åº“")
        st.stop()
        
    # --- é…ç½®åŒºåŸŸ ---
    with st.container():
        c1, c2 = st.columns(2)
        batch_size = c1.number_input("æ¯æ‰¹æ¬¡è¯„è®ºæ¡æ•° (é˜²æ­¢æ¨¡å‹æˆªæ–­)", min_value=10, max_value=200, value=30)
        target_group = c2.selectbox("å¤„ç†ç›®æ ‡", ["è‡ªåŠ¨å¤„ç†æ‰€æœ‰æ˜Ÿçº§", "ä»… 1-3 æ˜Ÿ (å·®è¯„)", "ä»… 4 æ˜Ÿ (æ‘‡æ‘†)", "ä»… 5 æ˜Ÿ (å¥½è¯„)"])

    # --- æ ¸å¿ƒ Prompt æ¨¡æ¿æ„å»ºé€»è¾‘ ---
    def build_prompt(data_chunk, rating_mode):
        """
        data_chunk: JSON list of reviews
        rating_mode: '1-3', '4', '5'
        """
        # è·å–æ ‡ç­¾
        pos_tags = json.dumps(st.session_state.tag_config['pos'], ensure_ascii=False)
        neg_tags = json.dumps(st.session_state.tag_config['neg'], ensure_ascii=False)
        
        # åŸºç¡€ç³»ç»ŸæŒ‡ä»¤
        sys_prompt = """## Role
You are an expert e-commerce review classifier.
## Output Format
Strictly valid JSON list: [{"id": "...", "label": "..."}]
Do not add any markdown blocks or explanations outside the JSON.
## Constraints
1. Only use tags from the provided lists.
2. If no tag fits, return empty string for label."""

        # åŠ¨æ€ä»»åŠ¡æŒ‡ä»¤ (æ ¸å¿ƒé€»è¾‘)
        if rating_mode == '1-3':
            task_prompt = f"""## Task (Negative Focus)
These are low-rated reviews (1-3 stars).
Please select the best match from this **NEGATIVE TAG LIST**:
{neg_tags}"""
        elif rating_mode == '5':
            task_prompt = f"""## Task (Positive Focus)
These are high-rated reviews (5 stars).
Please select the best match from this **POSITIVE TAG LIST**:
{pos_tags}"""
        else: # 4 Stars
            task_prompt = f"""## Task (Critical Analysis)
These are 4-star reviews. They are tricky.
**Rule 1**: First check for ANY complaints. Prioritize this **NEGATIVE TAG LIST**:
{neg_tags}
**Rule 2**: If absolutely no complaints, check this **POSITIVE TAG LIST**:
{pos_tags}
**Rule 3**: Negative tags have HIGHER PRIORITY than positive ones."""

        # ç»„è£…
        payload = json.dumps(data_chunk, ensure_ascii=False, indent=2)
        return f"{sys_prompt}\n\n{task_prompt}\n\n## Data Payload\n{payload}"

    if st.button("ğŸš€ ç”Ÿæˆ Prompt æ‰¹æ¬¡", type="primary"):
        df = st.session_state.normalized_df
        batches = []
        
        # å®šä¹‰åˆ†ç»„ç­–ç•¥
        groups = {}
        if target_group in ["è‡ªåŠ¨å¤„ç†æ‰€æœ‰æ˜Ÿçº§", "ä»… 1-3 æ˜Ÿ (å·®è¯„)"]:
            groups['1-3'] = df[df['rating'] <= 3]
        if target_group in ["è‡ªåŠ¨å¤„ç†æ‰€æœ‰æ˜Ÿçº§", "ä»… 4 æ˜Ÿ (æ‘‡æ‘†)"]:
            groups['4'] = df[df['rating'] == 4]
        if target_group in ["è‡ªåŠ¨å¤„ç†æ‰€æœ‰æ˜Ÿçº§", "ä»… 5 æ˜Ÿ (å¥½è¯„)"]:
            groups['5'] = df[df['rating'] == 5]
            
        # å¾ªç¯åˆ‡ç‰‡
        for g_name, g_df in groups.items():
            if g_df.empty: continue
            
            # è½¬å­—å…¸åˆ—è¡¨
            records = g_df.to_dict(orient='records')
            
            # åˆ‡åˆ†
            for i in range(0, len(records), batch_size):
                chunk = records[i:i+batch_size]
                prompt_text = build_prompt(chunk, g_name)
                
                batches.append({
                    "name": f"[{g_name}æ˜Ÿ] ç¬¬ {i//batch_size + 1} æ‰¹ (å…±{len(chunk)}æ¡)",
                    "prompt": prompt_text,
                    "count": len(chunk)
                })
        
        st.session_state.generated_batches = batches
        st.success(f"å·²ç”Ÿæˆ {len(batches)} ä¸ªä»»åŠ¡åŒ…ï¼")

    # --- å±•ç¤ºæ‰¹æ¬¡å¡ç‰‡ ---
    if st.session_state.generated_batches:
        for idx, batch in enumerate(st.session_state.generated_batches):
            with st.expander(f"ğŸ“¦ {batch['name']}", expanded=(idx==0)):
                st.text_area("Prompt (ç‚¹å‡»å³ä¸Šè§’å¤åˆ¶)", value=batch['prompt'], height=200, key=f"b_{idx}")
                st.caption("ğŸ‘† å…¨é€‰å¤åˆ¶ä¸Šé¢çš„å†…å®¹ï¼Œå‘é€ç»™ ChatGPT / Claude / DeepSeek")

# ------------------------------------------
# Tab 4: ç»“æœå›å¡«
# ------------------------------------------
with tab4:
    st.header("Step 4: ç»“æœå›å¡«ä¸åˆå¹¶")
    
    col_input, col_preview = st.columns([1, 1])
    
    with col_input:
        st.markdown("### 1. ç²˜è´´ LLM è¿”å›çš„ JSON")
        json_input = st.text_area("åœ¨æ­¤ç²˜è´´...", height=300, placeholder='[{"id":"...", "label":"..."}, ...]')
        
        if st.button("è§£æå¹¶æ ¡éªŒ"):
            data = safe_json_parse(json_input)
            if data:
                res_df = pd.DataFrame(data)
                
                # åŸºç¡€æ ¡éªŒ
                if 'id' not in res_df.columns or 'label' not in res_df.columns:
                    st.error("âŒ æ ¼å¼é”™è¯¯ï¼šJSON å¿…é¡»åŒ…å« 'id' å’Œ 'label' å­—æ®µ")
                else:
                    # æ ‡ç­¾åˆæ³•æ€§æ ¡éªŒ
                    valid_tags = set(st.session_state.tag_config['all'])
                    # å¦‚æœè¿˜æ²¡å¯¼æ ‡ç­¾åº“ï¼Œæš‚æ—¶è·³è¿‡æ ¡éªŒ
                    if not valid_tags:
                        res_df['is_valid'] = True
                    else:
                        res_df['is_valid'] = res_df['label'].apply(
                            lambda x: x in valid_tags or x == "" or x is None
                        )
                    
                    invalid_count = len(res_df[~res_df['is_valid']])
                    
                    if invalid_count > 0:
                        st.warning(f"âš ï¸ å‘ç° {invalid_count} ä¸ªéæ³•æ ‡ç­¾ï¼ˆä¸åœ¨åº“å†…ï¼‰ï¼Œå°†æ ‡è®°ä¸º INVALID_TAG")
                        res_df.loc[~res_df['is_valid'], 'label'] = "INVALID_TAG"
                    else:
                        st.success("âœ… æ‰€æœ‰æ ‡ç­¾æ ¡éªŒé€šè¿‡ï¼")
                    
                    # å­˜å…¥ Session æš‚å­˜ä»¥ä¾¿ä¸‹è½½
                    st.session_state.temp_result_df = res_df
            else:
                st.error("æ— æ³•è§£æï¼Œè¯·æ£€æŸ¥æ˜¯å¦å®Œæ•´å¤åˆ¶äº† [ ... ]")

    with col_preview:
        st.markdown("### 2. åˆå¹¶å›ä¸»è¡¨")
        if 'temp_result_df' in st.session_state:
            res_df = st.session_state.temp_result_df
            st.dataframe(res_df)
            
            if st.button("ğŸ”„ ç¡®è®¤åˆå¹¶åˆ°ä¸»è¡¨", type="primary"):
                # å‡†å¤‡ä¸»è¡¨
                main = st.session_state.main_df
                
                # ç¡®å®šä¸»è¡¨çš„ ID åˆ—
                # å¦‚æœ Step 1 ç”Ÿæˆäº† sys_uuidï¼Œç”¨å®ƒï¼›å¦åˆ™ç”¨ç”¨æˆ·æŒ‡å®šçš„åˆ—
                if 'sys_uuid' in main.columns:
                    join_key = 'sys_uuid'
                elif 'id' in st.session_state.normalized_df.columns:
                    # è¿™ç§æƒ…å†µæ¯”è¾ƒå¤æ‚ï¼Œç®€å•èµ·è§ï¼Œæˆ‘ä»¬åœ¨ Step 1 å·²ç»æŠŠ sys_uuid å†™å…¥ main äº†
                    join_key = 'sys_uuid' 
                else:
                    # å…œåº•ï¼šå‡è®¾ç”¨æˆ·ç¬¬ä¸€æ­¥é€‰äº† ID åˆ—ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾å›é‚£ä¸ªåˆ—å
                    # è¿™é‡Œä¸ºäº†ä»£ç å¥å£®æ€§ï¼Œå»ºè®®å¼ºä¾èµ– Step 1 çš„ uuid
                    st.error("æ— æ³•å®šä½ä¸»è¡¨ IDï¼Œè¯·é‡æ–°åœ¨ Step 1 ç”Ÿæˆ UUID")
                    st.stop()

                # åˆ›å»ºå­—å…¸æ˜ å°„
                id_map = dict(zip(res_df['id'], res_df['label']))
                
                # åˆ›å»ºæ–°åˆ—å (é˜²æ­¢è¦†ç›–)
                new_col = 'AI_Label'
                if new_col not in main.columns:
                    main[new_col] = None
                
                # æ›´æ–°é€»è¾‘
                def update_row(row):
                    rid = str(row[join_key])
                    if rid in id_map:
                        return id_map[rid]
                    return row[new_col] # ä¿æŒåŸæ ·

                main[new_col] = main.apply(update_row, axis=1)
                st.session_state.main_df = main
                st.success(f"å·²æˆåŠŸæ›´æ–° {len(res_df)} æ¡æ•°æ®ï¼")

    st.markdown("---")
    st.header("ğŸ“¥ ä¸‹è½½æœ€ç»ˆè¡¨æ ¼")
    
    if st.session_state.main_df is not None:
        final_df = st.session_state.main_df
        
        # CSV ä¸‹è½½
        csv_data = final_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            "ä¸‹è½½ CSV æ ¼å¼",
            data=csv_data,
            file_name="tagged_reviews_final.csv",
            mime="text/csv"
        )
        
        # Excel ä¸‹è½½ (éœ€ openpyxl)
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            final_df.to_excel(writer, index=False, sheet_name='Sheet1')
        
        st.download_button(
            "ä¸‹è½½ Excel æ ¼å¼",
            data=buffer.getvalue(),
            file_name="tagged_reviews_final.xlsx",
            mime="application/vnd.ms-excel"
        )