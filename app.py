import streamlit as st
import pandas as pd
import json
import uuid
import io

# ==========================================
# 0. åŸºç¡€é…ç½®ä¸å®‰å…¨ç™»å½•
# ==========================================
st.set_page_config(
    page_title="LLM è¯„è®ºæ™ºèƒ½æ‰“æ ‡ (æ€ç»´é“¾ç‰ˆ)", 
    page_icon="ğŸ§ ", 
    layout="wide"
)

# --- ç®€å•çš„å¯†ç ä¿æŠ¤ ---
ACCESS_PASSWORD = "admin123" 

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state["password_input"] == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop() 

# ==========================================
# 1. Session State åˆå§‹åŒ–
# ==========================================
if 'main_df' not in st.session_state: st.session_state.main_df = None
if 'normalized_df' not in st.session_state: st.session_state.normalized_df = None
if 'tag_config' not in st.session_state: st.session_state.tag_config = {"pos": [], "neg": [], "all": []}
if 'generated_batches' not in st.session_state: st.session_state.generated_batches = []
if 'temp_result_df' not in st.session_state: st.session_state.temp_result_df = None

# ==========================================
# 2. å·¥å…·å‡½æ•°
# ==========================================
def load_file(uploaded_file):
    try:
        if uploaded_file.name.endswith('.csv'):
            try:
                return pd.read_csv(uploaded_file, encoding='utf-8')
            except UnicodeDecodeError:
                return pd.read_csv(uploaded_file, encoding='gbk')
        else:
            return pd.read_excel(uploaded_file)
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None

def safe_json_parse(json_str):
    if not json_str: return None
    try:
        clean_str = json_str.replace("```json", "").replace("```", "").strip()
        return json.loads(clean_str)
    except json.JSONDecodeError:
        return None

# ==========================================
# 3. é¡µé¢ä¸»ä½“
# ==========================================
st.title("ğŸ§  è¯„è®ºæ•°æ®åˆ†æä¸æ‰“æ ‡ç³»ç»Ÿ (æ€ç»´é“¾å¢å¼ºç‰ˆ)")

tab1, tab2, tab3, tab4 = st.tabs(["1. æ•°æ®çœ‹æ¿ & æ¸…æ´—", "2. è¯„ä»·åº“é…ç½®", "3. ç”Ÿæˆ Prompt (Updated)", "4. ç»“æœå›å¡«"])

# ------------------------------------------
# Tab 1: æ•°æ®å¯¼å…¥ & å¯è§†åŒ–çœ‹æ¿
# ------------------------------------------
with tab1:
    st.header("Step 1: æ•°æ®å¯¼å…¥ä¸æ¦‚è§ˆ")
    uploaded_file = st.file_uploader("ä¸Šä¼  Excel/CSV æ–‡ä»¶", type=['csv', 'xlsx'])

    if uploaded_file:
        df_raw = load_file(uploaded_file)
        
        if df_raw is not None:
            st.info(f"ğŸ“„ æ–‡ä»¶è¯»å–æˆåŠŸï¼æ£€æµ‹åˆ° **{len(df_raw)}** è¡Œæ•°æ®ã€‚")
            st.dataframe(df_raw.head(3))

            st.markdown("---")
            st.subheader("ğŸ”§ å…³é”®å­—æ®µè®¾ç½®")
            
            all_cols = df_raw.columns.tolist()
            c1, c2, c3, c4 = st.columns(4)
            
            idx_rating = all_cols.index('rating') if 'rating' in all_cols else 0
            idx_content = all_cols.index('content') if 'content' in all_cols else 0
            idx_date = all_cols.index('date') if 'date' in all_cols else 0
            
            with c1: col_rating = st.selectbox("Rating (æ˜Ÿçº§)", all_cols, index=idx_rating)
            with c2: col_content = st.selectbox("Content (å†…å®¹)", all_cols, index=idx_content)
            with c3: col_date = st.selectbox("Date (æ—¶é—´ - å¯é€‰)", ["--ä¸åˆ†æ--"] + all_cols, index=idx_date + 1 if 'date' in all_cols else 0)
            with c4: col_id_opt = st.selectbox("ID (å”¯ä¸€æ ‡è¯†)", ["-- è‡ªåŠ¨ç”Ÿæˆ UUID --"] + all_cols)

            if st.button("ç”Ÿæˆçœ‹æ¿å¹¶æ ‡å‡†åŒ–", type="primary"):
                clean_df = df_raw.copy()
                
                # æ¸…æ´—æ˜Ÿçº§
                clean_df['rating_numeric'] = pd.to_numeric(clean_df[col_rating], errors='coerce')
                clean_df = clean_df.dropna(subset=['rating_numeric'])
                clean_df['rating_int'] = clean_df['rating_numeric'].round().astype(int)
                clean_df = clean_df[clean_df['rating_int'].between(1, 5)]

                # æ¸…æ´—æ—¶é—´
                time_parse_success = False
                if col_date != "--ä¸åˆ†æ--":
                    clean_df['date_parsed'] = pd.to_datetime(clean_df[col_date], errors='coerce')
                    if clean_df['date_parsed'].notna().sum() > 0: time_parse_success = True

                # IDå¤„ç†
                if col_id_opt.startswith("--"):
                    clean_df['sys_uuid'] = [str(uuid.uuid4())[:8] for _ in range(len(clean_df))]
                    target_id_col = 'sys_uuid'
                else:
                    clean_df[col_id_opt] = clean_df[col_id_opt].astype(str)
                    target_id_col = col_id_opt

                st.session_state.main_df = clean_df
                st.session_state.normalized_df = clean_df[[target_id_col, 'rating_int', col_content]].rename(
                    columns={target_id_col: 'id', 'rating_int': 'rating', col_content: 'text'}
                )
                
                # çœ‹æ¿
                st.markdown("---")
                k1, k2, k3 = st.columns(3)
                total = len(clean_df)
                neg_rate = (len(clean_df[clean_df['rating_int'] <= 3]) / total * 100) if total > 0 else 0
                k1.metric("æœ‰æ•ˆè¯„è®ºæ•°", total)
                k2.metric("å¹³å‡åˆ†", f"{clean_df['rating_int'].mean():.2f}")
                k3.metric("å·®è¯„ç‡", f"{neg_rate:.1f}%")

                c_chart1, c_chart2 = st.columns(2)
                with c_chart1:
                    counts = clean_df['rating_int'].value_counts().reindex([1,2,3,4,5], fill_value=0).sort_index()
                    st.bar_chart(counts)
                with c_chart2:
                    if time_parse_success:
                        st.line_chart(clean_df.set_index('date_parsed').resample('M').size())
                    else:
                        st.info("æš‚æ— æ—¶é—´è¶‹åŠ¿æ•°æ®")

                st.success("âœ… æ•°æ®å‡†å¤‡å°±ç»ª")

# ------------------------------------------
# Tab 2: è¯„ä»·åº“é…ç½®
# ------------------------------------------
with tab2:
    st.header("Step 2: å¯¼å…¥æ ‡ç­¾åº“")
    st.info("è¡¨å¤´éœ€åŒ…å«: `label`, `polarity` (positive/negative)")
    tag_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾åº“", type=['csv', 'xlsx'], key="tag_uploader")
    
    if tag_file:
        tag_df = load_file(tag_file)
        if tag_df is not None:
            c1, c2 = st.columns(2)
            lbl_col = c1.selectbox("æ ‡ç­¾åˆ—", tag_df.columns)
            pol_col = c2.selectbox("ææ€§åˆ—", tag_df.columns)
            
            if st.button("åŠ è½½æ ‡ç­¾"):
                tag_df['p_lower'] = tag_df[pol_col].astype(str).str.lower()
                pos = tag_df[tag_df['p_lower'].str.contains('pos|good|å¥½|æ­£')][lbl_col].dropna().unique().tolist()
                neg = tag_df[tag_df['p_lower'].str.contains('neg|bad|å·®|è´Ÿ')][lbl_col].dropna().unique().tolist()
                
                st.session_state.tag_config = {"pos": pos, "neg": neg, "all": list(set(pos + neg))}
                st.success(f"å·²åŠ è½½: å¥½è¯„ {len(pos)} ä¸ª, å·®è¯„ {len(neg)} ä¸ª")

# ------------------------------------------
# Tab 3: Prompt ç”Ÿæˆ (é‡ç‚¹æ›´æ–°)
# ------------------------------------------
with tab3:
    st.header("Step 3: ç”Ÿæˆæ€ç»´é“¾ Prompt")
    st.markdown("ğŸ’¡ **æ–°é€»è¾‘**ï¼šæ¨¡å‹å°†å…ˆç”Ÿæˆâ€œä¸´æ—¶æ€»ç»“æ ‡ç­¾â€ï¼Œå†æ˜ å°„åˆ°æ ‡å‡†åº“ã€‚")
    
    if st.session_state.normalized_df is None:
        st.warning("è¯·å…ˆå®Œæˆ Step 1")
        st.stop()

    batch_size = st.number_input("æ¯æ‰¹æ¡æ•°", value=30, min_value=10)
    
    def build_prompt(data_chunk, rating_mode):
        pos_tags_str = ", ".join([f'"{t}"' for t in st.session_state.tag_config['pos']])
        neg_tags_str = ", ".join([f'"{t}"' for t in st.session_state.tag_config['neg']])
        
        # System Prompt: è®¾å®š JSON è¾“å‡ºæ ¼å¼
        system_part = """You are an expert customer review analyzer.
Your goal is to assign a standardized summary tag to each review.
OUTPUT FORMAT: Strictly Valid JSON list: [{"id": "...", "label": "..."}].
Do not output CSV text or explanations, only the JSON structure."""

        # Shared Logic: å®šä¹‰æ€ç»´é“¾è¿‡ç¨‹
        reasoning_logic = """
### THINKING PROCESS (Internal Step):
1. **Analyze**: Read the review content carefully.
2. **Draft Temporary Label**: Mentally generate a "Temporary Generic Summary Label" that best describes the review content.
3. **Map to Library**: Compare your "Temporary Label" with the provided [STANDARD TAG LIBRARY] below.
4. **Final Decision**: 
   - If your temporary label matches (or is a synonym of) a tag in the Library, output the **Library Tag**.
   - If the review does not fit any tag in the Library, output an empty string "".
"""

        if rating_mode == '1-3':
            task_part = f"""
{reasoning_logic}
### CONTEXT
These are 1-3 Star reviews (Negative). 
**STANDARD TAG LIBRARY (Negative)**:
[{neg_tags_str}]
"""
        elif rating_mode == '5':
            task_part = f"""
{reasoning_logic}
### CONTEXT
These are 5 Star reviews (Positive).
**STANDARD TAG LIBRARY (Positive)**:
[{pos_tags_str}]
"""
        else: # 4 star
            task_part = f"""
{reasoning_logic}
### CONTEXT
These are 4 Star reviews (Ambiguous).
**STANDARD TAG LIBRARY (Combined)**:
- **Positive List**: [{pos_tags_str}]
- **Negative List**: [{neg_tags_str}]

**Priority Rule**: If the review contains ANY complaint, prioritize the Negative List. Otherwise, use the Positive List.
"""
        data_part = f"DATA PAYLOAD:\n{json.dumps(data_chunk, ensure_ascii=False, indent=2)}"
        return f"{system_part}\n{task_part}\n{data_part}"

    if st.button("ç”Ÿæˆ Prompt"):
        df = st.session_state.normalized_df
        batches = []
        
        groups = {
            '1-3': df[df['rating'] <= 3],
            '4':   df[df['rating'] == 4],
            '5':   df[df['rating'] == 5]
        }
        
        for r_mode, g_df in groups.items():
            if g_df.empty: continue
            records = g_df.to_dict(orient='records')
            for i in range(0, len(records), batch_size):
                chunk = records[i:i+batch_size]
                prompt_text = build_prompt(chunk, r_mode)
                batches.append({
                    "title": f"[{r_mode}æ˜Ÿç»„] æ‰¹æ¬¡ {i//batch_size + 1} ({len(chunk)}æ¡)",
                    "prompt": prompt_text
                })
        
        st.session_state.generated_batches = batches
        st.success(f"å·²ç”Ÿæˆ {len(batches)} ä¸ªä»»åŠ¡åŒ…")

    for b in st.session_state.generated_batches:
        with st.expander(b["title"]):
            st.text_area("Prompt", b["prompt"], height=200)
            st.caption("å¤åˆ¶ä¸Šæ–¹å†…å®¹å‘é€ç»™ AIã€‚AI ä¼šåœ¨å†…éƒ¨è¿›è¡Œâ€˜ä¸´æ—¶æ€»ç»“->æ ‡å‡†æ˜ å°„â€™çš„è¿‡ç¨‹ï¼Œä½†æœ€ç»ˆåªè¿”å›ç¬¦åˆæ ¼å¼çš„ JSONã€‚")

# ------------------------------------------
# Tab 4: ç»“æœå›å¡«
# ------------------------------------------
with tab4:
    st.header("Step 4: ç»“æœå›å¡«")
    json_input = st.text_area("ç²˜è´´ LLM è¿”å›çš„ JSON", height=200)
    
    if st.button("åˆå¹¶ç»“æœ"):
        data = safe_json_parse(json_input)
        if data:
            res_df = pd.DataFrame(data)
            if 'id' in res_df.columns and 'label' in res_df.columns:
                main = st.session_state.main_df
                id_col = 'sys_uuid' if 'sys_uuid' in main.columns else st.session_state.normalized_df.columns[0]
                
                id_map = dict(zip(res_df['id'], res_df['label']))
                
                if 'AI_Label' not in main.columns: main['AI_Label'] = None
                
                main['AI_Label'] = main.apply(
                    lambda row: id_map.get(str(row.get(id_col)), row['AI_Label']), axis=1
                )
                
                st.session_state.main_df = main
                st.success(f"åˆå¹¶æˆåŠŸï¼")
                st.dataframe(main[['rating_int', 'AI_Label']].head())
            else:
                st.error("JSON æ ¼å¼é”™è¯¯")
        else:
            st.error("JSON è§£æå¤±è´¥")

    if st.session_state.main_df is not None:
        csv = st.session_state.main_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ä¸‹è½½ç»“æœ CSV", csv, "tagged_result.csv", "text/csv")
