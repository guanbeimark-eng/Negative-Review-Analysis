import streamlit as st
import pandas as pd
import json
import uuid

# ==========================================
# 0. åŸºç¡€é…ç½®ä¸å®‰å…¨ç™»å½•
# ==========================================
st.set_page_config(
    page_title="LLM è¯„è®ºæ™ºèƒ½æ‰“æ ‡",
    page_icon="ğŸ·ï¸",
    layout="wide"
)

ACCESS_PASSWORD = "admin123"

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state.get("password_input") == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop()

# ==========================================
# 1. Session State åˆå§‹åŒ–
# ==========================================
if "main_df" not in st.session_state: st.session_state.main_df = None
if "normalized_df" not in st.session_state: st.session_state.normalized_df = None
if "tag_config" not in st.session_state: st.session_state.tag_config = {"pos": [], "neg": [], "all": []}
if "generated_batches" not in st.session_state: st.session_state.generated_batches = []
if "id_col_in_main" not in st.session_state: st.session_state.id_col_in_main = None  # âœ…å…³é”®ï¼šä¿å­˜ä¸»è¡¨é‡Œçš„IDåˆ—å

# ==========================================
# 2. å·¥å…·å‡½æ•°
# ==========================================
def load_file(uploaded_file):
    try:
        name = uploaded_file.name.lower()
        if name.endswith(".csv"):
            try:
                return pd.read_csv(uploaded_file, encoding="utf-8")
            except UnicodeDecodeError:
                return pd.read_csv(uploaded_file, encoding="gbk")
        return pd.read_excel(uploaded_file)
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None

def safe_json_parse_maybe_multi(json_str: str):
    """æ”¯æŒç²˜è´´å¤šæ®µ JSONï¼šå¯ä»¥æ˜¯å•ä¸ªlistï¼Œä¹Ÿå¯ä»¥æ˜¯å¤šæ®µlistæ‹¼ä¸€èµ·ï¼ˆç”¨æ¢è¡Œåˆ†éš”ï¼‰ã€‚"""
    if not json_str:
        return None
    clean = json_str.replace("```json", "").replace("```", "").strip()
    if not clean:
        return None

    # å…ˆå°è¯•æ•´ä½“è§£æ
    try:
        obj = json.loads(clean)
        return obj
    except Exception:
        pass

    # å°è¯•æŒ‰æ®µè½æ‹†åˆ†è§£æå¹¶åˆå¹¶
    parts = [p.strip() for p in clean.split("\n\n") if p.strip()]
    merged = []
    ok_any = False
    for p in parts:
        try:
            obj = json.loads(p)
            if isinstance(obj, list):
                merged.extend(obj)
                ok_any = True
        except Exception:
            continue
    return merged if ok_any else None

def normalize_polarity(x: str) -> str:
    s = str(x).strip().lower()
    # å¸¸è§å†™æ³•å®¹é”™
    if s in ["positive", "pos", "good", "å¥½è¯„", "æ­£å‘", "æ­£"]:
        return "positive"
    if s in ["negative", "neg", "bad", "å·®è¯„", "è´Ÿå‘", "è´Ÿ"]:
        return "negative"
    # æ¨¡ç³ŠåŒ¹é…
    if any(k in s for k in ["pos", "good", "å¥½", "æ­£"]): return "positive"
    if any(k in s for k in ["neg", "bad", "å·®", "è´Ÿ"]): return "negative"
    return ""

def validate_label(label: str, allowed_set: set) -> str:
    """ä¸¥æ ¼æ ¡éªŒï¼šåªå…è®¸åº“å†…æ ‡ç­¾ï¼›å¦åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²"""
    if label is None:
        return ""
    lab = str(label).strip()
    return lab if lab in allowed_set else ""

# ==========================================
# 3. é¡µé¢ä¸»ä½“
# ==========================================
st.title("ğŸ·ï¸ è¯„è®ºæ•°æ®æ‰“æ ‡ç³»ç»Ÿï¼ˆæŒ‰è¯„ä»·åº“æ ‡ç­¾è¾“å‡ºï¼‰")
tab1, tab2, tab3, tab4 = st.tabs(["1. æ•°æ®çœ‹æ¿ & æ¸…æ´—", "2. è¯„ä»·åº“é…ç½®", "3. ç”Ÿæˆ Prompt", "4. ç»“æœå›å¡«"])

# ------------------------------------------
# Tab 1: æ•°æ®å¯¼å…¥ & å¯è§†åŒ–çœ‹æ¿
# ------------------------------------------
with tab1:
    st.header("Step 1: æ•°æ®å¯¼å…¥ä¸æ¦‚è§ˆ")
    uploaded_file = st.file_uploader("ä¸Šä¼  Excel/CSV æ–‡ä»¶", type=["csv", "xlsx"])

    if uploaded_file:
        df_raw = load_file(uploaded_file)
        if df_raw is not None:
            st.info(f"ğŸ“„ æ–‡ä»¶è¯»å–æˆåŠŸï¼æ£€æµ‹åˆ° **{len(df_raw)}** è¡Œæ•°æ®ã€‚")
            st.dataframe(df_raw.head(5))

            st.markdown("---")
            st.subheader("ğŸ”§ å…³é”®å­—æ®µè®¾ç½®")

            all_cols = df_raw.columns.tolist()
            c1, c2, c3, c4, c5 = st.columns(5)

            idx_rating = all_cols.index("rating") if "rating" in all_cols else 0
            idx_title  = all_cols.index("title") if "title" in all_cols else 0
            idx_content = all_cols.index("content") if "content" in all_cols else 0
            idx_date = all_cols.index("date") if "date" in all_cols else None

            with c1: col_rating = st.selectbox("Rating (æ˜Ÿçº§)", all_cols, index=idx_rating)
            with c2: col_title = st.selectbox("Title (æ ‡é¢˜-å¯é€‰)", ["--ä¸ä½¿ç”¨--"] + all_cols, index=(idx_title + 1) if "title" in all_cols else 0)
            with c3: col_content = st.selectbox("Content (å†…å®¹)", all_cols, index=idx_content)
            with c4:
                date_options = ["--ä¸åˆ†æ--"] + all_cols
                col_date = st.selectbox("Date (æ—¶é—´-å¯é€‰)", date_options, index=(idx_date + 1) if idx_date is not None else 0)
            with c5: col_id_opt = st.selectbox("ID (å”¯ä¸€æ ‡è¯†)", ["-- è‡ªåŠ¨ç”Ÿæˆ UUID --"] + all_cols)

            if st.button("ç”Ÿæˆçœ‹æ¿å¹¶æ ‡å‡†åŒ–", type="primary"):
                clean_df = df_raw.copy()

                # æ˜Ÿçº§æ¸…æ´—
                clean_df["rating_numeric"] = pd.to_numeric(clean_df[col_rating], errors="coerce")
                clean_df = clean_df.dropna(subset=["rating_numeric"])
                clean_df["rating_int"] = clean_df["rating_numeric"].round().astype(int)
                clean_df = clean_df[clean_df["rating_int"].between(1, 5)]

                # æ—¶é—´æ¸…æ´—ï¼ˆå¯é€‰ï¼‰
                time_parse_success = False
                if col_date != "--ä¸åˆ†æ--":
                    clean_df["date_parsed"] = pd.to_datetime(clean_df[col_date], errors="coerce")
                    time_parse_success = clean_df["date_parsed"].notna().sum() > 0

                # IDå¤„ç†ï¼ˆâœ…ä¿å­˜ä¸»è¡¨IDåˆ—åï¼‰
                if col_id_opt.startswith("--"):
                    clean_df["sys_uuid"] = [str(uuid.uuid4())[:8] for _ in range(len(clean_df))]
                    st.session_state.id_col_in_main = "sys_uuid"
                else:
                    clean_df[col_id_opt] = clean_df[col_id_opt].astype(str)
                    st.session_state.id_col_in_main = col_id_opt

                # æ–‡æœ¬æ‹¼æ¥ï¼ˆtitleå¯é€‰ï¼‰
                if col_title != "--ä¸ä½¿ç”¨--":
                    clean_df["__text_joined__"] = (
                        clean_df[col_title].fillna("").astype(str).str.strip()
                        + " | "
                        + clean_df[col_content].fillna("").astype(str).str.strip()
                    ).str.strip(" |")
                    text_col = "__text_joined__"
                else:
                    text_col = col_content

                st.session_state.main_df = clean_df

                # è§„èŒƒåŒ–è¡¨ï¼ˆä¾›promptï¼‰
                st.session_state.normalized_df = clean_df[
                    [st.session_state.id_col_in_main, "rating_int", text_col]
                ].rename(columns={
                    st.session_state.id_col_in_main: "id",
                    "rating_int": "rating",
                    text_col: "text"
                })

                # çœ‹æ¿
                st.markdown("---")
                total = len(clean_df)
                neg_rate = (len(clean_df[clean_df["rating_int"] <= 3]) / total * 100) if total else 0
                k1, k2, k3 = st.columns(3)
                k1.metric("æœ‰æ•ˆè¯„è®ºæ•°", total)
                k2.metric("å¹³å‡åˆ†", f"{clean_df['rating_int'].mean():.2f}" if total else "N/A")
                k3.metric("å·®è¯„ç‡(<=3æ˜Ÿ)", f"{neg_rate:.1f}%")

                c_chart1, c_chart2 = st.columns(2)
                with c_chart1:
                    counts = clean_df["rating_int"].value_counts().reindex([1,2,3,4,5], fill_value=0).sort_index()
                    st.bar_chart(counts)
                with c_chart2:
                    if time_parse_success:
                        # æœˆåº¦è¶‹åŠ¿
                        tmp = clean_df.dropna(subset=["date_parsed"]).set_index("date_parsed")
                        st.line_chart(tmp.resample("M").size())
                    else:
                        st.info("æš‚æ— æ—¶é—´è¶‹åŠ¿æ•°æ®æˆ–æ—¶é—´åˆ—è§£æå¤±è´¥")

                st.success("âœ… æ•°æ®å‡†å¤‡å°±ç»ª")

# ------------------------------------------
# Tab 2: è¯„ä»·åº“é…ç½®
# ------------------------------------------
with tab2:
    st.header("Step 2: å¯¼å…¥æ ‡ç­¾åº“")
    st.info("å»ºè®®è¡¨å¤´åŒ…å«: `label`, `polarity`ï¼ˆpositive/negative æˆ– å¥½è¯„/å·®è¯„ï¼‰")

    tag_file = st.file_uploader("ä¸Šä¼ æ ‡ç­¾åº“", type=["csv", "xlsx"], key="tag_uploader")

    if tag_file:
        tag_df = load_file(tag_file)
        if tag_df is not None:
            c1, c2 = st.columns(2)
            lbl_col = c1.selectbox("æ ‡ç­¾åˆ—(label)", tag_df.columns)
            pol_col = c2.selectbox("ææ€§åˆ—(polarity)", tag_df.columns)

            if st.button("åŠ è½½æ ‡ç­¾"):
                tmp = tag_df.copy()
                tmp["pol_norm"] = tmp[pol_col].apply(normalize_polarity)

                pos = tmp[tmp["pol_norm"] == "positive"][lbl_col].dropna().astype(str).unique().tolist()
                neg = tmp[tmp["pol_norm"] == "negative"][lbl_col].dropna().astype(str).unique().tolist()

                st.session_state.tag_config = {"pos": pos, "neg": neg, "all": list(dict.fromkeys(pos + neg))}
                st.success(f"âœ… å·²åŠ è½½: å¥½è¯„ {len(pos)} ä¸ª, å·®è¯„ {len(neg)} ä¸ª")

    # å±•ç¤ºå½“å‰åº“
    st.markdown("---")
    st.subheader("å½“å‰å·²åŠ è½½æ ‡ç­¾é¢„è§ˆ")
    st.write({"å¥½è¯„æ ‡ç­¾æ•°": len(st.session_state.tag_config["pos"]), "å·®è¯„æ ‡ç­¾æ•°": len(st.session_state.tag_config["neg"])})
    with st.expander("æŸ¥çœ‹å¥½è¯„æ ‡ç­¾"):
        st.write(st.session_state.tag_config["pos"])
    with st.expander("æŸ¥çœ‹å·®è¯„æ ‡ç­¾"):
        st.write(st.session_state.tag_config["neg"])

# ------------------------------------------
# Tab 3: Prompt ç”Ÿæˆ
# ------------------------------------------
with tab3:
    st.header("Step 3: ç”Ÿæˆ Promptï¼ˆ4æ˜Ÿä¼˜å…ˆå·®è¯„ç‚¹ï¼‰")

    if st.session_state.normalized_df is None:
        st.warning("è¯·å…ˆå®Œæˆ Step 1ï¼šæ•°æ®å¯¼å…¥ä¸æ ‡å‡†åŒ–")
        st.stop()

    if (not st.session_state.tag_config["pos"]) or (not st.session_state.tag_config["neg"]):
        st.warning("è¯·å…ˆå®Œæˆ Step 2ï¼šåŠ è½½æ ‡ç­¾åº“ï¼ˆéœ€è¦åŒæ—¶æœ‰å¥½è¯„ä¸å·®è¯„æ ‡ç­¾ï¼‰")
        st.stop()

    batch_size = st.number_input("æ¯æ‰¹æ¡æ•°", value=30, min_value=10, max_value=200, step=10)

    def build_prompt(data_chunk, rating_mode):
        pos_tags_str = ", ".join([f'"{t}"' for t in st.session_state.tag_config["pos"]])
        neg_tags_str = ", ".join([f'"{t}"' for t in st.session_state.tag_config["neg"]])

        system_part = (
            "You are an expert customer review tagger.\n"
            "You MUST select labels ONLY from the provided tag library.\n"
            "Return STRICT JSON only, no explanations, no extra text.\n"
            'Output schema: [{"id": "...", "label": ""}] where label is either a library tag or empty string.\n'
        )

        if rating_mode == "1-3":
            task_part = f"""
TASK:
These are 1-3 star reviews. You MUST choose from NEGATIVE tag library only.
If no suitable tag, output "".

NEGATIVE TAG LIBRARY:
[{neg_tags_str}]
"""
        elif rating_mode == "5":
            task_part = f"""
TASK:
These are 5 star reviews. You MUST choose from POSITIVE tag library only.
If no suitable tag, output "".

POSITIVE TAG LIBRARY:
[{pos_tags_str}]
"""
        else:  # 4-star
            task_part = f"""
TASK:
These are 4 star reviews. PRIORITIZE complaints.
Rule:
1) If the review contains ANY complaint/negative point, choose from NEGATIVE tag library.
2) Otherwise choose from POSITIVE tag library.
3) If still no suitable tag, output "".

POSITIVE TAG LIBRARY:
[{pos_tags_str}]

NEGATIVE TAG LIBRARY:
[{neg_tags_str}]
"""

        data_part = "DATA (JSON):\n" + json.dumps(data_chunk, ensure_ascii=False, indent=2)
        return f"{system_part}\n{task_part}\n{data_part}"

    if st.button("ç”Ÿæˆ Prompt"):
        df = st.session_state.normalized_df
        batches = []

        groups = {
            "1-3": df[df["rating"] <= 3],
            "4":   df[df["rating"] == 4],
            "5":   df[df["rating"] == 5],
        }

        for r_mode, g_df in groups.items():
            if g_df.empty:
                continue
            records = g_df.to_dict(orient="records")
            for i in range(0, len(records), int(batch_size)):
                chunk = records[i:i+int(batch_size)]
                prompt_text = build_prompt(chunk, r_mode)
                batches.append({
                    "title": f"[{r_mode}æ˜Ÿ] æ‰¹æ¬¡ {i//int(batch_size)+1}ï¼ˆ{len(chunk)}æ¡ï¼‰",
                    "prompt": prompt_text
                })

        st.session_state.generated_batches = batches
        st.success(f"âœ… å·²ç”Ÿæˆ {len(batches)} ä¸ªä»»åŠ¡åŒ…")

    for b in st.session_state.generated_batches:
        with st.expander(b["title"]):
            st.text_area("Promptï¼ˆå¤åˆ¶ç»™æ¨¡å‹ï¼‰", b["prompt"], height=260)

# ------------------------------------------
# Tab 4: ç»“æœå›å¡«
# ------------------------------------------
with tab4:
    st.header("Step 4: ç»“æœå›å¡«ï¼ˆä¸¥æ ¼æ ¡éªŒåº“å†…æ ‡ç­¾ï¼‰")

    if st.session_state.main_df is None or st.session_state.normalized_df is None:
        st.warning("è¯·å…ˆå®Œæˆ Step 1")
        st.stop()

    allowed_set = set(st.session_state.tag_config["all"])
    json_input = st.text_area("ç²˜è´´ LLM è¿”å›çš„ JSONï¼ˆå¯ä¸€æ¬¡ç²˜è´´å¤šæ‰¹æ¬¡ï¼‰", height=220)

    if st.button("åˆå¹¶ç»“æœ"):
        data = safe_json_parse_maybe_multi(json_input)
        if not data or not isinstance(data, list):
            st.error("JSON è§£æå¤±è´¥ï¼šè¯·ç¡®ä¿è¿”å›çš„æ˜¯ JSON listï¼Œä¾‹å¦‚ï¼š[{'id':'xxx','label':'...'}]")
        else:
            res_df = pd.DataFrame(data)
            if "id" not in res_df.columns or "label" not in res_df.columns:
                st.error("JSON æ ¼å¼é”™è¯¯ï¼šå¿…é¡»åŒ…å« id ä¸ label å­—æ®µ")
            else:
                # âœ…ä¸¥æ ¼æ ¡éªŒlabel
                res_df["id"] = res_df["id"].astype(str)
                res_df["label"] = res_df["label"].apply(lambda x: validate_label(x, allowed_set))

                # ç»Ÿè®¡åº“å¤–æ ‡ç­¾ï¼ˆè¢«ç½®ç©ºçš„æ•°é‡ï¼‰
                invalid_cnt = (pd.Series([x.get("label") for x in data]).astype(str).apply(lambda s: s.strip()).apply(lambda s: s != "" and s not in allowed_set)).sum()

                id_map = dict(zip(res_df["id"], res_df["label"]))

                main = st.session_state.main_df
                id_col = st.session_state.id_col_in_main  # âœ…å‡†ç¡®ä½¿ç”¨ä¸»è¡¨IDåˆ—
                main[id_col] = main[id_col].astype(str)

                if "AI_Label" not in main.columns:
                    main["AI_Label"] = ""

                main["AI_Label"] = main[id_col].map(id_map).fillna(main["AI_Label"]).astype(str)

                st.session_state.main_df = main
                st.success(f"âœ… åˆå¹¶æˆåŠŸï¼æœ¬æ¬¡åˆå¹¶ {len(res_df)} æ¡ï¼›åº“å¤–æ ‡ç­¾å·²è‡ªåŠ¨ç½®ç©ºï¼ˆä¼°ç®— {invalid_cnt} æ¡ï¼‰ã€‚")
                st.dataframe(main[[id_col, "rating_int", "AI_Label"]].head(20))

    if st.session_state.main_df is not None:
        csv = st.session_state.main_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ä¸‹è½½ç»“æœ CSV", csv, "tagged_result.csv", "text/csv")
