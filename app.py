import streamlit as st
import pandas as pd
import numpy as np
import re
import math
from collections import Counter, defaultdict

# =========================
# é¡µé¢é…ç½®
# =========================
st.set_page_config(
    page_title="è¯„è®ºè‡ªåŠ¨æ‰“æ ‡ç³»ç»Ÿï¼ˆæ•°æ®é©±åŠ¨æƒé‡ç‰ˆï¼‰",
    page_icon="ğŸ·ï¸",
    layout="wide"
)

# =========================
# æ ‡ç­¾ä¸»é¢˜å®šä¹‰ï¼ˆåªå®šä¹‰â€œè¯­ä¹‰æ¡¶â€ï¼Œä¸å†™å…³é”®è¯ï¼‰
# =========================
NEGATIVE_TOPICS = {
    "å°ºç åå°": ["small", "tight"],
    "å°ºç åå¤§": ["big", "large", "loose"],
    "ä¸èˆ’é€‚ / å‹’æ‰‹": ["uncomfortable", "pain", "hurt"],
    "ç©¿æˆ´å›°éš¾": ["hard", "difficult"],
    "æ”¯æ’‘ä¸è¶³": ["support"],
    "è´¨é‡å·® / æ˜“æŸ": ["broke", "cheap", "poor"],
    "ä¸æè¿°ä¸ç¬¦": ["describe", "different"],
    "å·®è¯„-å…¶ä»–é—®é¢˜": []
}

POSITIVE_TOPICS = {
    "ä½©æˆ´èˆ’é€‚": ["comfortable", "soft"],
    "å°ºå¯¸åˆé€‚": ["perfect", "true"],
    "æ”¯æ’‘æ€§å¥½": ["support"],
    "ç¼“è§£ç–¼ç—›": ["relief", "pain"],
    "è´¨é‡å¥½": ["well", "quality"],
    "æ€§ä»·æ¯”é«˜": ["worth", "value"],
    "å¥½è¯„-æ•´ä½“æ»¡æ„": []
}

# =========================
# å·¥å…·å‡½æ•°
# =========================
def load_file(f):
    if f.name.lower().endswith(".csv"):
        return pd.read_csv(f, encoding="utf-8", errors="ignore")
    return pd.read_excel(f)

def parse_rating(x):
    if pd.isna(x):
        return np.nan
    m = re.search(r"(\d+(\.\d+)?)", str(x))
    return float(m.group(1)) if m else np.nan

def tokenize(text):
    text = re.sub(r"[^a-zA-Z\s]", " ", text.lower())
    words = text.split()
    bigrams = [f"{words[i]} {words[i+1]}" for i in range(len(words)-1)]
    return words + bigrams

# =========================
# å…³é”®è¯æƒé‡å­¦ä¹ 
# =========================
def learn_keyword_weights(texts, ratings):
    neg_counter = Counter()
    pos_counter = Counter()

    for text, r in zip(texts, ratings):
        tokens = tokenize(text)
        if r <= 3:
            neg_counter.update(tokens)
        elif r == 5:
            pos_counter.update(tokens)

    weights = {}
    vocab = set(neg_counter) | set(pos_counter)
    for w in vocab:
        fn = neg_counter[w]
        fp = pos_counter[w]
        if fn + fp < 3:
            continue
        weight_neg = math.log((fn + 1) / (fp + 1))
        weight_pos = math.log((fp + 1) / (fn + 1))
        weights[w] = (weight_neg, weight_pos)
    return weights

def score_text(text, topic_keywords, weights, mode):
    score = 0.0
    tokens = tokenize(text)
    for t in tokens:
        if t in weights:
            w_neg, w_pos = weights[t]
            if mode == "neg":
                score += w_neg
            else:
                score += w_pos
    return score

def choose_label(text, rating, weights):
    if rating <= 3:
        scores = {
            tag: score_text(text, kws, weights, "neg")
            for tag, kws in NEGATIVE_TOPICS.items()
        }
        best = max(scores, key=scores.get)
        return best if scores[best] > 0 else "å·®è¯„-å…¶ä»–é—®é¢˜"

    if rating == 5:
        scores = {
            tag: score_text(text, kws, weights, "pos")
            for tag, kws in POSITIVE_TOPICS.items()
        }
        best = max(scores, key=scores.get)
        return best if scores[best] > 0 else "å¥½è¯„-æ•´ä½“æ»¡æ„"

    # 4 æ˜Ÿï¼šä¼˜å…ˆå·®è¯„
    neg_scores = {
        tag: score_text(text, kws, weights, "neg")
        for tag, kws in NEGATIVE_TOPICS.items()
    }
    best_neg = max(neg_scores, key=neg_scores.get)
    if neg_scores[best_neg] > 0:
        return best_neg

    pos_scores = {
        tag: score_text(text, kws, weights, "pos")
        for tag, kws in POSITIVE_TOPICS.items()
    }
    best_pos = max(pos_scores, key=pos_scores.get)
    return best_pos if pos_scores[best_pos] > 0 else "å¥½è¯„-æ•´ä½“æ»¡æ„"

# =========================
# ä¸»ç•Œé¢
# =========================
st.title("ğŸ·ï¸ è¯„è®ºè‡ªåŠ¨æ‰“æ ‡ç³»ç»Ÿï¼ˆå…³é”®è¯æƒé‡å­¦ä¹ ç‰ˆï¼‰")

uploaded = st.file_uploader("ä¸Šä¼ è¯„è®ºæ–‡ä»¶ï¼ˆCSV / Excelï¼‰", type=["csv", "xlsx"])

if uploaded:
    df = load_file(uploaded)

    cols = df.columns.tolist()
    col_rating = next((c for c in cols if "rating" in c.lower() or "æ˜Ÿ" in c), None)
    col_text = next((c for c in cols if "content" in c.lower() or "review" in c.lower() or "ç¿»è¯‘" in c), None)

    if not col_rating or not col_text:
        st.error("æ— æ³•è¯†åˆ«æ˜Ÿçº§æˆ–è¯„è®ºå†…å®¹åˆ—")
        st.stop()

    df["rating"] = df[col_rating].apply(parse_rating).round().astype("Int64")
    df = df[df["rating"].between(1, 5)]
    df["text"] = df[col_text].astype(str)

    # å­¦ä¹ æƒé‡
    weights = learn_keyword_weights(df["text"], df["rating"])

    # æ‰“æ ‡
    df["AI_Label"] = df.apply(lambda r: choose_label(r["text"], r["rating"], weights), axis=1)

    # æŒ‡æ ‡
    neg_rate = (df["rating"] <= 3).mean() * 100

    st.subheader("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
    c1, c2, c3 = st.columns(3)
    c1.metric("æœ‰æ•ˆè¯„è®ºæ•°", len(df))
    c2.metric("å¹³å‡æ˜Ÿçº§", f"{df['rating'].mean():.2f}")
    c3.metric("å·®è¯„å æ¯”(â‰¤3â­)", f"{neg_rate:.1f}%")

    st.bar_chart(df["rating"].value_counts().sort_index())

    st.subheader("ğŸ·ï¸ æ‰“æ ‡ç»“æœé¢„è§ˆ")
    st.dataframe(df[["rating", "AI_Label", "text"]].head(20))

    out = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "â¬‡ï¸ ä¸‹è½½æ•°æ®é©±åŠ¨æ‰“æ ‡ç»“æœ CSV",
        out,
        "tagged_reviews_weighted.csv",
        "text/csv"
    )
