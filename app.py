import streamlit as st
import pandas as pd
import json
import uuid
import re
import numpy as np

# =========================
# 0) App Config + Login
# =========================
st.set_page_config(page_title="LLM è¯„è®ºæ‰“æ ‡ï¼ˆå‚»ç“œå¼ï¼‰", page_icon="ğŸ·ï¸", layout="wide")

ACCESS_PASSWORD = "admin123"
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state.get("password_input") == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop()

# =========================
# 1) å†…ç½®è¯„ä»·åº“ï¼ˆé»˜è®¤ï¼‰
#    ä½ åé¢æŠŠè¿™å—æ›¿æ¢æˆä½ ä»¬â€œæ–‡ä»¶è¯„ä»·åº“â€çš„æ­£å¼æ ‡ç­¾å³å¯
# =========================
TAG_LIBRARY = {
    "positive": [
        "ä½©æˆ´èˆ’é€‚", "æ”¯æ’‘æ€§å¥½", "ç¼“è§£å…³èŠ‚ä¸é€‚", "å°ºå¯¸åˆé€‚", "è´¨é‡å¥½", "æ€§ä»·æ¯”é«˜", "æ•ˆæœæ˜æ˜¾", "ç‰©æµ/å‘è´§å¿«", "å¤–è§‚å¥½çœ‹"
    ],
    "negative": [
        "å°ºç åå°", "å°ºç åå¤§", "å°ºç ä¸ä¸€è‡´", "ä¸é€‚åˆç”·å£«", "ç©¿æˆ´å›°éš¾", "è´¨é‡å·®", "ä¸æè¿°ä¸ç¬¦", "ä¸èˆ’é€‚/å‹’æ‰‹", "æ°”å‘³/å¼‚å‘³", "è€ç”¨æ€§å·®/æ˜“ç ´", "å‹åŠ›/å‹ç¼©æ„Ÿä¸è¶³"
    ]
}

# =========================
# 2) Session State
# =========================
defaults = {
    "raw_df": None,
    "main_df": None,          # æ¸…æ´—åä¸»è¡¨ï¼ˆä¿ç•™åŸå­—æ®µ + rating_int + sys_idï¼‰
    "norm_df": None,          # id/rating/text ï¼ˆç»™æ¨¡å‹ç”¨ï¼‰
    "full_df": None,          # ä¸»è¡¨+AI_Label åˆå¹¶å¯¼å‡º

    "col_map": None,
    "tag_config": {"pos": TAG_LIBRARY["positive"], "neg": TAG_LIBRARY["negative"], "all": TAG_LIBRARY["positive"] + TAG_LIBRARY["negative"]},
    "prompts": [],

    "step": 1,                # å¯¼èˆªæ­¥è¿›ï¼š1-4
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# =========================
# 3) Utils
# =========================
def load_file(f):
    name = f.name.lower()
    if name.endswith(".csv"):
        try:
            return pd.read_csv(f, encoding="utf-8")
        except UnicodeDecodeError:
            return pd.read_csv(f, encoding="gbk")
    return pd.read_excel(f)

def parse_rating(x):
    """å…¼å®¹ rating: '4.0 out of 5 stars' / 'Rated 3' / '5' / 4.0"""
    if pd.isna(x):
        return np.nan
    s = str(x)
    m = re.search(r"(\d+(?:\.\d+)?)", s)
    if not m:
        return np.nan
    try:
        return float(m.group(1))
    except:
        return np.nan

COLUMN_CANDIDATES = {
    "rating": ["æ˜Ÿçº§", "rating", "Rating", "è¯„åˆ†", "Score"],
    "title": ["æ ‡é¢˜", "title", "Title", "headline", "summary"],
    "content": ["å†…å®¹", "content", "Content", "review", "Review", "è¯„è®ºå†…å®¹", "body", "text"],
    "translation": ["å†…å®¹(ç¿»è¯‘)", "ç¿»è¯‘", "translation", "Translated", "å†…å®¹ï¼ˆç¿»è¯‘ï¼‰"],
    "date": ["è¯„è®ºæ—¶é—´", "date", "Date", "review_date", "time", "æ—¶é—´", "è¯„è®ºæ—¥æœŸ"],
    "id": ["review_id", "id", "ID", "è¯„è®ºID", "uuid", "å”¯ä¸€ID"],
}

def auto_match_column(cols, candidates):
    # ç²¾ç¡®
    for c in candidates:
        if c in cols:
            return c
    # æ¨¡ç³ŠåŒ…å«
    for cand in candidates:
        cl = cand.lower()
        for col in cols:
            if cl in col.lower():
                return col
    return None

def auto_build_mapping(df):
    cols = df.columns.tolist()
    col_rating = auto_match_column(cols, COLUMN_CANDIDATES["rating"])
    col_title = auto_match_column(cols, COLUMN_CANDIDATES["title"])
    col_content = auto_match_column(cols, COLUMN_CANDIDATES["content"])
    col_trans = auto_match_column(cols, COLUMN_CANDIDATES["translation"])
    col_date = auto_match_column(cols, COLUMN_CANDIDATES["date"])
    col_id = auto_match_column(cols, COLUMN_CANDIDATES["id"])

    text_primary = col_trans or col_content
    return {
        "rating": col_rating,
        "title": col_title,
        "text": text_primary,
        "date": col_date,
        "id": col_id,
        "content_raw": col_content,
        "translation": col_trans
    }

def build_cleaned_frames(df_raw, m):
    tmp = df_raw.copy()

    # rating
    tmp["rating_numeric"] = tmp[m["rating"]].apply(parse_rating) if m.get("rating") else np.nan
    invalid_rating_cnt = int(tmp["rating_numeric"].isna().sum())

    valid = tmp.dropna(subset=["rating_numeric"]).copy()
    valid["rating_int"] = valid["rating_numeric"].round().astype(int)
    valid = valid[valid["rating_int"].between(1, 5)]

    # date
    time_ok = False
    if m.get("date") and m["date"] in valid.columns:
        valid["date_parsed"] = pd.to_datetime(valid[m["date"]], errors="coerce")
        time_ok = valid["date_parsed"].notna().sum() > 0

    # sys_idï¼ˆä¼˜å…ˆç”¨è¯†åˆ«åˆ°çš„idåˆ—ï¼Œå¦åˆ™ç”Ÿæˆï¼‰
    if m.get("id") and m["id"] in valid.columns:
        valid["sys_id"] = valid[m["id"]].astype(str)
    else:
        valid["sys_id"] = [str(uuid.uuid4())[:8] for _ in range(len(valid))]

    # textï¼ˆtitleå¯é€‰æ‹¼æ¥ï¼‰
    if m.get("text") is None:
        valid["__text__"] = ""
    else:
        if m.get("title") and m["title"] in valid.columns:
            valid["__text__"] = (
                valid[m["title"]].fillna("").astype(str).str.strip()
                + " | "
                + valid[m["text"]].fillna("").astype(str).str.strip()
            ).str.strip(" |")
        else:
            valid["__text__"] = valid[m["text"]].fillna("").astype(str)

    norm = valid[["sys_id", "rating_int", "__text__"]].rename(columns={
        "sys_id": "id",
        "rating_int": "rating",
        "__text__": "text"
    }).copy()

    return valid, norm, invalid_rating_cnt, time_ok

def safe_parse_json(text):
    """æ”¯æŒå¸¦ ```json```ã€ä»¥åŠå¤šæ®µ JSON list ç²˜è´´"""
    if not text:
        return None
    clean = text.replace("```json", "").replace("```", "").strip()
    if not clean:
        return None
    try:
        return json.loads(clean)
    except:
        pass
    parts = [p.strip() for p in clean.split("\n\n") if p.strip()]
    merged = []
    ok = False
    for p in parts:
        try:
            obj = json.loads(p)
            if isinstance(obj, list):
                merged.extend(obj)
                ok = True
        except:
            continue
    return merged if ok else None

def extract_id_label_list(obj):
    """
    å®¹é”™æå–ï¼š
    - æ ‡å‡†ï¼š[{id,label}]
    - å˜ä½“ï¼š[{id,AI_Label}] / [{id,tag}] / [{id,Label}]
    """
    if not isinstance(obj, list):
        return None, "ä¸æ˜¯ list"
    if len(obj) == 0:
        return None, "ç©º list"

    # æ‰¾å¯èƒ½çš„labelå­—æ®µ
    label_keys = ["label", "AI_Label", "ai_label", "tag", "Label", "æ ‡ç­¾", "åˆ†ç±»"]
    out = []
    miss = 0

    for item in obj:
        if not isinstance(item, dict):
            miss += 1
            continue
        _id = item.get("id")
        if _id is None:
            miss += 1
            continue
        found = None
        for k in label_keys:
            if k in item:
                found = item.get(k)
                break
        if found is None:
            # è¿™é‡Œè¯´æ˜ä½ ç²˜è´´çš„æ˜¯ {id,rating,text} è¿™ç§ï¼Œä¸å«label
            out.append({"id": str(_id), "label": None})
        else:
            out.append({"id": str(_id), "label": "" if found is None else str(found).strip()})

    # å¦‚æœå…¨éƒ¨éƒ½æ²¡æœ‰labelå€¼ï¼ˆå…¨æ˜¯Noneï¼‰ï¼Œå°±åˆ¤å®šâ€œç²˜è´´é”™äº†/æ¨¡å‹æ²¡æŒ‰æ ¼å¼è¾“å‡ºâ€
    if all(x["label"] is None for x in out):
        return out, "ç¼ºå°‘ label å­—æ®µï¼ˆä½ ç²˜è´´çš„å¯èƒ½æ˜¯è¯„è®ºæ•°æ®è€Œä¸æ˜¯æ¨¡å‹æ‰“æ ‡ç»“æœï¼‰"

    # å°† None å˜æˆç©ºä¸²
    for x in out:
        if x["label"] is None:
            x["label"] = ""

    return out, None

def build_fix_prompt_from_bad_output(bad_json_text):
    """
    ç»™ç”¨æˆ·ä¸€æ®µâ€œçº é”™æç¤ºè¯â€ï¼š
    æŠŠæ¨¡å‹è¾“å‡ºè½¬æˆæ­£ç¡®æ ¼å¼
    """
    return f"""è¯·æŠŠä¸‹é¢è¿™æ®µå†…å®¹è½¬æ¢ä¸ºä¸¥æ ¼ JSON listï¼Œä»…ä¿ç•™æ¯æ¡çš„ id å’Œ label ä¸¤ä¸ªå­—æ®µï¼š
- è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ï¼š[{{"id":"...","label":"..."}}]
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ–‡å­—ï¼Œä¸è¦è¾“å‡º ``` åŒ…è£¹
- label å¿…é¡»ä»æˆ‘æä¾›çš„æ ‡ç­¾åº“ä¸­é€‰æ‹©ï¼›ä¸åŒ¹é…å°±è¾“å‡ºç©ºå­—ç¬¦ä¸² ""

åŸå§‹å†…å®¹å¦‚ä¸‹ï¼š
{bad_json_text}
"""

# =========================
# 4) é¡¶éƒ¨å‚»ç“œå¼å¯¼èˆªï¼ˆä¸ç”¨ç‚¹å¾ˆå¤šæŒ‰é’®ï¼‰
# =========================
st.caption("æµç¨‹ï¼šâ‘  ä¸Šä¼ è¯„è®º&è‡ªåŠ¨æ˜ å°„  â†’ â‘¡ è¯„ä»·åº“ï¼ˆå¯é€‰ç¼–è¾‘ï¼‰ â†’ â‘¢ ç”Ÿæˆ Promptï¼ˆ4æ˜Ÿä¼˜å…ˆå·®è¯„ï¼‰ â†’ â‘£ ç²˜è´´JSONå›å¡«å¯¼å‡º")
step = st.session_state.step

nav = st.columns(4)
if nav[0].button("1 ä¸Šä¼ &è‡ªåŠ¨æ˜ å°„", use_container_width=True):
    st.session_state.step = 1
if nav[1].button("2 è¯„ä»·åº“", use_container_width=True):
    st.session_state.step = 2
if nav[2].button("3 ç”ŸæˆPrompt", use_container_width=True):
    st.session_state.step = 3
if nav[3].button("4 å›å¡«&å¯¼å‡º", use_container_width=True):
    st.session_state.step = 4

st.markdown("---")

# =========================
# Step 1ï¼šä¸Šä¼ &è‡ªåŠ¨æ˜ å°„ï¼ˆè‡ªåŠ¨å®Œæˆï¼šæ¸…æ´—+çœ‹æ¿+é”å®šï¼‰
# =========================
if st.session_state.step == 1:
    st.header("Step 1ï¼šä¸Šä¼ è¯„è®ºæ–‡ä»¶ï¼ˆç³»ç»Ÿè‡ªåŠ¨å®Œæˆæ˜ å°„/æ¸…æ´—/çœ‹æ¿ï¼‰")

    uploaded = st.file_uploader("ä¸Šä¼ è¯„è®ºæ•°æ®ï¼ˆCSV / Excelï¼‰", type=["csv", "xlsx"])
    if uploaded:
        df_raw = load_file(uploaded)
        st.session_state.raw_df = df_raw

        # è‡ªåŠ¨æ˜ å°„
        m = auto_build_mapping(df_raw)
        st.session_state.col_map = m

        # å¿…è¦åˆ—æ£€æŸ¥
        if not m.get("rating") or not m.get("text"):
            st.error("âŒ è‡ªåŠ¨è¯†åˆ«å¤±è´¥ï¼šç¼ºå°‘ rating æˆ– text åˆ—ã€‚è¯·æ¢ä¸€ä¸ªæ–‡ä»¶æˆ–æŠŠåˆ—åæ”¹æˆå¸¸è§å‘½åï¼ˆå¦‚ æ˜Ÿçº§ / å†…å®¹ / å†…å®¹(ç¿»è¯‘)ï¼‰ã€‚")
            st.json(m)
            st.stop()

        # è‡ªåŠ¨æ¸…æ´—å¹¶é”å®šï¼ˆå…³é”®ï¼šä¸éœ€è¦ç”¨æˆ·ç‚¹æŒ‰é’®ï¼‰
        valid, norm, invalid_cnt, time_ok = build_cleaned_frames(df_raw, m)
        st.session_state.main_df = valid
        st.session_state.norm_df = norm
        st.session_state.full_df = None  # å›å¡«åæ‰ç”Ÿæˆ

        # çœ‹æ¿ï¼ˆè‡ªåŠ¨å±•ç¤ºï¼‰
        raw_total = len(df_raw)
        valid_total = len(valid)
        neg_cnt = int((valid["rating_int"] <= 3).sum())
        neg_rate = (neg_cnt / valid_total * 100) if valid_total else 0
        severe_cnt = int((valid["rating_int"] <= 2).sum())
        severe_rate = (severe_cnt / valid_total * 100) if valid_total else 0

        st.success(f"âœ… æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼šåŸå§‹ {raw_total} è¡Œ / æœ‰æ•ˆè¯„åˆ† {valid_total} è¡Œ / è§£æå¤±è´¥ {invalid_cnt} è¡Œ")
        k1, k2, k3, k4, k5 = st.columns(5)
        k1.metric("åŸå§‹è¡Œæ•°", raw_total)
        k2.metric("æœ‰æ•ˆè¯„åˆ†", valid_total)
        k3.metric("è§£æå¤±è´¥", invalid_cnt)
        k4.metric("å·®è¯„å æ¯”(â‰¤3â­)", f"{neg_rate:.1f}%")
        k5.metric("ä¸¥é‡å·®è¯„(â‰¤2â­)", f"{severe_rate:.1f}%")

        st.subheader("â­ æ˜Ÿçº§åˆ†å¸ƒ")
        dist = valid["rating_int"].value_counts().reindex([1,2,3,4,5], fill_value=0).sort_index()
        st.bar_chart(dist)

        st.subheader("ğŸ“ LLM è¾“å…¥é¢„è§ˆï¼ˆå‰5æ¡ï¼‰")
        st.dataframe(norm.head(5))

        with st.expander("æŸ¥çœ‹ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«çš„åˆ—æ˜ å°„"):
            st.json(m)

        st.info("ä¸‹ä¸€æ­¥ï¼šç‚¹é¡¶éƒ¨ã€2 è¯„ä»·åº“ã€æˆ–ã€3 ç”ŸæˆPromptã€ç»§ç»­ã€‚")

# =========================
# Step 2ï¼šè¯„ä»·åº“ï¼ˆå¯é€‰ç¼–è¾‘ï¼‰
# =========================
if st.session_state.step == 2:
    st.header("Step 2ï¼šè¯„ä»·åº“ï¼ˆé»˜è®¤å·²å†…ç½®ï¼Œå¯é€‰ç¼–è¾‘ï¼‰")

    c1, c2 = st.columns(2)
    with c1:
        st.subheader("âœ… å¥½è¯„æ ‡ç­¾")
        pos_text = st.text_area("ä¸€è¡Œä¸€ä¸ªæ ‡ç­¾", value="\n".join(st.session_state.tag_config["pos"]), height=260)
    with c2:
        st.subheader("âŒ å·®è¯„æ ‡ç­¾")
        neg_text = st.text_area("ä¸€è¡Œä¸€ä¸ªæ ‡ç­¾", value="\n".join(st.session_state.tag_config["neg"]), height=260)

    if st.button("ä¿å­˜è¯„ä»·åº“"):
        pos = [x.strip() for x in pos_text.splitlines() if x.strip()]
        neg = [x.strip() for x in neg_text.splitlines() if x.strip()]
        st.session_state.tag_config = {"pos": pos, "neg": neg, "all": pos + neg}
        st.success(f"âœ… å·²ä¿å­˜ï¼šå¥½è¯„ {len(pos)} ä¸ª / å·®è¯„ {len(neg)} ä¸ª")

    st.info("ä¸‹ä¸€æ­¥ï¼šç‚¹é¡¶éƒ¨ã€3 ç”ŸæˆPromptã€ç»§ç»­ã€‚")

# =========================
# Step 3ï¼šç”Ÿæˆ Promptï¼ˆåªä¿ç•™ä¸€ä¸ªâ€œå¤åˆ¶â€åŠ¨ä½œï¼‰
# =========================
if st.session_state.step == 3:
    st.header("Step 3ï¼šç”Ÿæˆ Promptï¼ˆ4æ˜Ÿä¼˜å…ˆå·®è¯„ç‚¹ï¼‰")

    if st.session_state.norm_df is None:
        st.warning("è¯·å…ˆå» Step 1 ä¸Šä¼ è¯„è®ºæ•°æ®ã€‚")
        st.stop()

    df = st.session_state.norm_df
    pos_tags = st.session_state.tag_config["pos"]
    neg_tags = st.session_state.tag_config["neg"]

    batch_size = st.slider("æ¯æ‰¹æ¡æ•°ï¼ˆè¶Šå¤§è¶Šçœäº‹ï¼Œä½†æ¨¡å‹ä¸Šä¸‹æ–‡è¦å¤Ÿï¼‰", 20, 120, 60, 10)

    def build_prompt(chunk, mode):
        pos_str = ", ".join([f'"{t}"' for t in pos_tags])
        neg_str = ", ".join([f'"{t}"' for t in neg_tags])

        # å…³é”®ï¼šå¼ºåˆ¶åªè¾“å‡º id,label
        system = (
            "You are an expert customer review tagger.\n"
            "You MUST choose labels ONLY from the provided tag libraries.\n"
            "Return STRICT JSON ONLY. No explanations. No extra text.\n"
            "Output schema MUST be: [{\"id\":\"...\",\"label\":\"...\"}]\n"
            "If no suitable tag, label must be empty string \"\".\n"
        )

        if mode == "1-3":
            task = f"""
These are 1-3 star reviews.
Choose label ONLY from NEGATIVE TAG LIBRARY.
NEGATIVE TAG LIBRARY: [{neg_str}]
"""
        elif mode == "5":
            task = f"""
These are 5 star reviews.
Choose label ONLY from POSITIVE TAG LIBRARY.
POSITIVE TAG LIBRARY: [{pos_str}]
"""
        else:
            task = f"""
These are 4 star reviews. PRIORITIZE complaints.
Rule:
1) If ANY complaint/negative point exists, choose from NEGATIVE TAG LIBRARY.
2) Otherwise choose from POSITIVE TAG LIBRARY.
3) If no suitable tag, output "".
NEGATIVE TAG LIBRARY: [{neg_str}]
POSITIVE TAG LIBRARY: [{pos_str}]
"""

        data = "DATA (JSON):\n" + json.dumps(chunk, ensure_ascii=False, indent=2)
        return f"{system}\n{task}\n{data}"

    # è‡ªåŠ¨ç”Ÿæˆæ‰¹æ¬¡ï¼ˆæ— éœ€é¢å¤–æŒ‰é’®ï¼›æ”¹å˜ batch_size å°±ä¼šé‡ç®—ï¼‰
    prompts = []
    groups = {
        "1-3": df[df["rating"] <= 3],
        "4": df[df["rating"] == 4],
        "5": df[df["rating"] == 5],
    }
    for mode, gdf in groups.items():
        records = gdf.to_dict("records")
        for i in range(0, len(records), int(batch_size)):
            chunk = records[i:i+int(batch_size)]
            prompts.append({
                "title": f"[{mode}æ˜Ÿ] æ‰¹æ¬¡ {i//int(batch_size)+1}ï¼ˆ{len(chunk)}æ¡ï¼‰",
                "prompt": build_prompt(chunk, mode)
            })

    st.session_state.prompts = prompts
    st.success(f"âœ… å·²ç”Ÿæˆ {len(prompts)} ä¸ª Prompt æ‰¹æ¬¡ï¼ˆæ— éœ€å†ç‚¹ç”ŸæˆæŒ‰é’®ï¼‰")

    for b in prompts[:6]:
        with st.expander(b["title"]):
            st.text_area("å¤åˆ¶ç»™æ¨¡å‹ï¼ˆåªéœ€å¤åˆ¶ä¸€æ¬¡ï¼‰", b["prompt"], height=280)

    if len(prompts) > 6:
        st.info(f"è¿˜æœ‰ {len(prompts)-6} ä¸ªæ‰¹æ¬¡æœªå±•å¼€ï¼ˆä¸ºé¿å…é¡µé¢å¤ªé•¿ï¼‰ã€‚ä½ å¯ä»¥åœ¨ä»£ç é‡Œæ”¹æˆå…¨å±•å¼€ã€‚")

    st.info("ä¸‹ä¸€æ­¥ï¼šæŠŠæ¨¡å‹è¿”å›çš„ JSON ç²˜è´´åˆ°ã€4 å›å¡«&å¯¼å‡ºã€ã€‚")

# =========================
# Step 4ï¼šå›å¡«ï¼ˆç²˜è´´åè‡ªåŠ¨åˆ¤æ–­ã€è‡ªåŠ¨æç¤ºçº é”™ï¼‰
# =========================
if st.session_state.step == 4:
    st.header("Step 4ï¼šç²˜è´´æ¨¡å‹ JSON â†’ è‡ªåŠ¨å›å¡« â†’ ä¸€é”®å¯¼å‡º")

    if st.session_state.norm_df is None:
        st.warning("è¯·å…ˆå®Œæˆ Step 1ã€‚")
        st.stop()

    allowed_set = set(st.session_state.tag_config["all"])

    st.caption("ä½ åº”è¯¥ç²˜è´´æ¨¡å‹çš„è¿”å›ç»“æœï¼šæ ¼å¼å¿…é¡»æ˜¯ JSON listï¼Œä¾‹å¦‚ï¼š"
               "[{\"id\":\"1bc3a5ae\",\"label\":\"å°ºç åå°\"}, ...]")

    json_text = st.text_area("ç²˜è´´ LLM è¿”å› JSONï¼ˆå¯ä¸€æ¬¡ç²˜è´´å¤šæ‰¹æ¬¡ï¼‰", height=240)

    # è¿™é‡Œä¿æŒä¸€ä¸ªæŒ‰é’®å³å¯ï¼ˆä¸å†è®©å®¢æˆ·ç‚¹å¾ˆå¤šæŒ‰é’®ï¼‰
    if st.button("âœ… å›å¡«å¹¶æ›´æ–°å¯¼å‡ºæ–‡ä»¶", type="primary"):
        parsed = safe_parse_json(json_text)
        if parsed is None:
            st.error("JSON è§£æå¤±è´¥ï¼šè¯·ç¡®è®¤ç²˜è´´çš„æ˜¯åˆæ³• JSONï¼ˆä¸è¦å¤¹å¸¦è§£é‡Šæ–‡å­—ï¼‰ã€‚")
            st.stop()

        extracted, err = extract_id_label_list(parsed)
        if err and "ç¼ºå°‘ label" in err:
            st.error("âŒ ä½ ç²˜è´´çš„ä¸æ˜¯ã€æ¨¡å‹æ‰“æ ‡ç»“æœã€ï¼Œé‡Œé¢æ²¡æœ‰ label å­—æ®µã€‚")
            st.info("ä½ ç²˜è´´çš„çœ‹èµ·æ¥åƒã€è¯„è®ºæ•°æ®ï¼ˆid/rating/textï¼‰ã€è€Œä¸æ˜¯ã€æ‰“æ ‡ç»“æœï¼ˆid/labelï¼‰ã€ã€‚")

            st.subheader("âœ… å¤åˆ¶ä¸‹é¢è¿™æ®µçº é”™æç¤ºè¯ï¼Œå‘ç»™æ¨¡å‹ï¼Œè®©å®ƒæŠŠè¾“å‡ºæ”¹æˆæ­£ç¡®æ ¼å¼")
            fix_prompt = build_fix_prompt_from_bad_output(json_text)
            st.code(fix_prompt, language="text")
            st.stop()

        if extracted is None:
            st.error(f"æ— æ³•æå– id/labelï¼š{err}")
            st.stop()

        # æ ¡éªŒ label å¿…é¡»æ¥è‡ªåº“
        for x in extracted:
            x["label"] = validate_label(x.get("label", ""), allowed_set)

        id_map = {x["id"]: x["label"] for x in extracted}

        # å›å¡«åˆ° normalized
        df = st.session_state.norm_df.copy()
        if "AI_Label" not in df.columns:
            df["AI_Label"] = ""
        df["AI_Label"] = df["id"].map(id_map).fillna(df["AI_Label"]).astype(str)
        st.session_state.norm_df = df

        st.success(f"âœ… å›å¡«å®Œæˆï¼šæœ¬æ¬¡å¤„ç† {len(extracted)} æ¡ï¼ˆåº“å¤–æ ‡ç­¾å·²è‡ªåŠ¨ç½®ç©ºï¼‰")
        st.dataframe(df.head(20))

        # åˆå¹¶å› full_df
        if st.session_state.main_df is not None:
            main = st.session_state.main_df.copy()
            lab = df[["id", "AI_Label"]].copy()
            main["sys_id"] = main["sys_id"].astype(str)
            lab["id"] = lab["id"].astype(str)
            merged = main.merge(lab, left_on="sys_id", right_on="id", how="left")
            merged.drop(columns=["id"], inplace=True, errors="ignore")
            st.session_state.full_df = merged

    st.markdown("---")
    st.subheader("å¯¼å‡º")

    out_norm = st.session_state.norm_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ ä¸‹è½½ï¼šnormalizedï¼ˆid/rating/text/AI_Labelï¼‰", out_norm, "tagged_reviews_normalized.csv", "text/csv")

    if st.session_state.full_df is not None:
        out_full = st.session_state.full_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("â¬‡ï¸ ä¸‹è½½ï¼šfullï¼ˆåŸå§‹å­—æ®µ+AI_Labelï¼‰", out_full, "tagged_reviews_full.csv", "text/csv")
