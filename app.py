import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sentence_transformers import SentenceTransformer, util
from sklearn.feature_extraction.text import CountVectorizer
import torch
import re
import io

# =========================
# 0. é¡µé¢é…ç½®ä¸å®‰å…¨éªŒè¯
# =========================
st.set_page_config(
    page_title="æ™ºèƒ½è¯„è®ºæ ‡ç­¾åˆ†æç³»ç»Ÿ (å¯è§†åŒ–ç‰ˆ)",
    page_icon="ğŸ“Š",
    layout="wide"
)

# è®¿é—®å¯†ç 
ACCESS_PASSWORD = "admin123" 

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

def check_password():
    if st.session_state["password_input"] == ACCESS_PASSWORD:
        st.session_state.logged_in = True
    else:
        st.error("å¯†ç é”™è¯¯")

if not st.session_state.logged_in:
    st.markdown("## ğŸ”’ ç³»ç»Ÿé”å®š")
    st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password", key="password_input", on_change=check_password)
    st.stop() 

# =========================
# 1. æ‚¨çš„æ ‡å‡†æ ‡ç­¾åº“ (ä¸­æ–‡ç‰ˆ)
# =========================
# AI å°†è‡ªåŠ¨è®¡ç®—è¿™äº›ä¸­æ–‡æ ‡ç­¾ä¸è‹±æ–‡/ä¸­æ–‡è¯„è®ºçš„ç›¸ä¼¼åº¦
POS_LABELS = [
    "é¢æ–™èˆ’é€‚/æŸ”è½¯", "åšå·¥è´¨é‡å¥½", "ç¼“è§£ç–¼ç—›/åŒ»ç–—æ•ˆæœ", "ä¿æš–æ€§èƒ½å¥½", 
    "å°ºç åˆèº«/èˆ’é€‚è´´åˆ", "æä¾›å‹ç¼©æ„Ÿ/æ”¯æ’‘åŠ›", "å¢åŠ æŠ“æ¡åŠ›/é˜²æ»‘", 
    "å…³èŠ‚ç‚/æ‰³æœºæŒ‡è¾…åŠ©", "çµæ´»æ€§å¥½", "è€ç”¨æ€§å¼º", "è½»ç›ˆé€æ°”"
]

NEG_LABELS = [
    "æ— æ•ˆ/æ²¡æœ‰ä½œç”¨", "ç¼çº¿å¼€è£‚/ç ´æŸ", "æ”¶åˆ°äºŒæ‰‹/è„æ±¡", "é¢æ–™è´¨é‡å·®/å»‰ä»·", 
    "å°ºç å¤ªå°/å¤ªç´§", "å°ºç å¤ªå¤§/å¤ªæ¾", "æ¥ç¼å¤„ç£¨æ‰‹/ä¸é€‚", "ä¸è€ç”¨/ä¸€æ¬¡æ€§", 
    "è¿‡æ•/çš®ç–¹/å‘ç—’", "å¤ªæ»‘/æ²¡æœ‰æŠ“æ¡åŠ›", "æ•°é‡ä¸ç¬¦/å‘é”™è´§", "å¯¼è‡´è¡€æ¶²å¾ªç¯å—é˜»"
]

# =========================
# 2. AI æ¨¡å‹åŠ è½½ (å‡çº§ä¸ºå¤šè¯­è¨€ç‰ˆ)
# =========================
@st.cache_resource
def load_model():
    # ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œè®© AI èƒ½ç†è§£ "Soft" = "æŸ”è½¯"
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# =========================
# 3. æ ¸å¿ƒåŠŸèƒ½ï¼šæ ‡ç­¾åŒ¹é…ä¸å‘ç°
# =========================
def extract_dynamic_label(text, model, ngram_range=(2, 3)):
    """
    å½“è¯„è®ºä¸åŒ¹é…æ ‡å‡†åº“æ—¶ï¼Œæå–åŸæ–‡æ ¸å¿ƒçŸ­è¯­ä½œä¸ºæ ‡ç­¾
    """
    try:
        # ç®€å•åˆ¤æ–­æ˜¯å¦åŒ…å«ä¸­æ–‡ï¼Œè°ƒæ•´åˆ†è¯ç­–ç•¥
        is_chinese = bool(re.search(r'[\u4e00-\u9fff]', text))
        analyzer_type = 'char' if is_chinese else 'word'
        
        # æå–å€™é€‰è¯
        count = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer_type, stop_words='english').fit([text])
        candidates = count.get_feature_names_out()
        
        if len(candidates) == 0: return "å…¶ä»–æœªåˆ†ç±»"

        # è®¡ç®—æœ€æ ¸å¿ƒçš„çŸ­è¯­
        doc_embedding = model.encode([text])
        candidate_embeddings = model.encode(candidates)
        distances = util.cos_sim(doc_embedding, candidate_embeddings)
        keywords = [candidates[index] for index in distances.argsort()[0][-1:]]
        
        # æ ¼å¼åŒ–è¾“å‡º
        tag = keywords[0]
        return tag.replace(" ", "") if is_chinese else tag.title()
        
    except:
        return "å…¶ä»–(æ–‡æœ¬è¿‡çŸ­)"

def semantic_classify_and_discover(df, model, match_threshold=0.40):
    """
    ä¸»é€»è¾‘ï¼šæ ‡å‡†åº“åŒ¹é… -> æƒ…æ„Ÿåˆ¤æ–­ -> æ–°è¯å‘ç°
    """
    reviews = df['text'].tolist()
    
    # æ‰¹é‡ç¼–ç  (é€Ÿåº¦æœ€å¿«çš„æ–¹å¼)
    review_embeddings = model.encode(reviews, convert_to_tensor=True)
    pos_embeddings = model.encode(POS_LABELS, convert_to_tensor=True)
    neg_embeddings = model.encode(NEG_LABELS, convert_to_tensor=True)
    
    pos_sims = util.cos_sim(review_embeddings, pos_embeddings)
    neg_sims = util.cos_sim(review_embeddings, neg_embeddings)
    
    final_labels = []
    sentiment_display = [] # ç”¨äºæ˜¾ç¤ºä¸­æ–‡æƒ…æ„Ÿ
    is_new_label = []

    # è¿›åº¦æ¡
    progress_bar = st.progress(0)
    total = len(df)
    
    for i in range(total):
        if i % 10 == 0: progress_bar.progress(i / total)

        rating = df.iloc[i]['rating']
        text = df.iloc[i]['text']
        
        best_pos_idx = torch.argmax(pos_sims[i]).item()
        best_pos_score = pos_sims[i][best_pos_idx].item()
        
        best_neg_idx = torch.argmax(neg_sims[i]).item()
        best_neg_score = neg_sims[i][best_neg_idx].item()
        
        label = None
        s_display = "æœªçŸ¥"
        is_new = False
        is_negative = False

        # --- æƒ…æ„Ÿåˆ¤å®š ---
        if rating <= 3:
            is_negative = True
        elif rating == 4:
            # 4æ˜Ÿæ‘‡æ‘†ï¼šè°åˆ†æ•°é«˜å¬è°çš„
            if best_neg_score > best_pos_score: is_negative = True
            else: is_negative = False
        else:
            is_negative = False

        # --- åŒ¹é…é€»è¾‘ ---
        if is_negative:
            s_display = "å·®è¯„"
            # 1. å°è¯•åŒ¹é…æ ‡å‡†å·®è¯„åº“
            if best_neg_score > match_threshold:
                label = NEG_LABELS[best_neg_idx]
            else:
                # 2. æŒ–æ˜æ–°æ ‡ç­¾
                label = extract_dynamic_label(text, model)
                is_new = True
        else:
            s_display = "å¥½è¯„"
            # 1. å°è¯•åŒ¹é…æ ‡å‡†å¥½è¯„åº“
            if best_pos_score > match_threshold:
                label = POS_LABELS[best_pos_idx]
            else:
                # 2. æŒ–æ˜æ–°æ ‡ç­¾
                label = extract_dynamic_label(text, model)
                is_new = True
        
        final_labels.append(label)
        sentiment_display.append(s_display)
        is_new_label.append(is_new)

    progress_bar.empty()
    return final_labels, sentiment_display, is_new_label

# =========================
# 4. è¾…åŠ©å·¥å…·
# =========================
def load_file(f):
    if f.name.lower().endswith(".csv"):
        try: return pd.read_csv(f, encoding="utf-8")
        except: return pd.read_csv(f, encoding="gbk")
    return pd.read_excel(f)

def parse_rating(x):
    if pd.isna(x): return np.nan
    m = re.search(r"(\d+(\.\d+)?)", str(x))
    return float(m.group(1)) if m else np.nan

# =========================
# 5. ä¸»ç¨‹åº UI
# =========================
st.title("ğŸ“Š æ™ºèƒ½è¯„è®ºæ ‡ç­¾åˆ†æç³»ç»Ÿ")
st.markdown("AI æ¨¡å‹ï¼š**Multilingual-MiniLM** (æ”¯æŒä¸­è‹±äº’è¯‘åŒ¹é…)")

with st.spinner("æ­£åœ¨åŠ è½½å¤šè¯­è¨€ AI æ¨¡å‹..."):
    model = load_model()

uploaded = st.file_uploader("ä¸Šä¼ è¯„è®ºæ–‡ä»¶ (CSV/Excel)", type=["csv", "xlsx"])

if uploaded:
    with st.spinner('AI æ­£åœ¨è¿›è¡Œè·¨è¯­è¨€è¯­ä¹‰åˆ†æ...'):
        df = load_file(uploaded)
        
        # å­—æ®µè¯†åˆ«
        all_cols = df.columns.tolist()
        rating_col = next((c for c in all_cols if "æ˜Ÿ" in c or "rating" in c.lower()), all_cols[0])
        text_col = next((c for c in all_cols if "å†…å®¹" in c or "review" in c.lower()), all_cols[1])
        
        # æ¸…æ´—
        df["rating"] = df[rating_col].apply(parse_rating).round().astype(int)
        df = df[df["rating"].between(1, 5)]
        df["text"] = df[text_col].astype(str).fillna("")
        
        # æ ¸å¿ƒè¿ç®—
        labels, sentiments, is_new = semantic_classify_and_discover(df, model)
        df["æ ‡ç­¾"] = labels
        df["æƒ…æ„Ÿåˆ†ç±»"] = sentiments
        df["æ˜¯å¦æ–°æ ‡ç­¾"] = is_new
        
    st.success("âœ… åˆ†æå®Œæˆï¼")

    # =========================
    # å¯è§†åŒ–æ¨¡å— A: å®è§‚æ¦‚è§ˆ
    # =========================
    st.markdown("---")
    st.header("1. æ•°æ®æ¦‚è§ˆ")
    
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("è¯„è®ºæ€»æ•°", len(df))
    k1.caption("æœ‰æ•ˆæ•°æ®è¡Œ")
    
    avg_score = df['rating'].mean()
    k2.metric("å¹³å‡è¯„åˆ†", f"{avg_score:.2f} â­")
    
    neg_count = len(df[df['æƒ…æ„Ÿåˆ†ç±»']=="å·®è¯„"])
    neg_rate = neg_count / len(df) * 100
    k3.metric("å·®è¯„å æ¯”", f"{neg_rate:.1f}%")
    
    new_tag_count = sum(is_new)
    k4.metric("æ–°å‘ç°é—®é¢˜ç‚¹", new_tag_count)
    k4.caption("æ ‡å‡†åº“æœªè¦†ç›–çš„åˆ†ç±»")

    # =========================
    # å¯è§†åŒ–æ¨¡å— B: å›¾è¡¨åˆ†æ
    # =========================
    st.markdown("---")
    st.header("2. å¯è§†åŒ–æ·±åº¦åˆ†æ")
    
    col_chart1, col_chart2 = st.columns(2)
    
    with col_chart1:
        st.subheader("æƒ…æ„Ÿæ„æˆåˆ†æ")
        # ç¯å½¢å›¾ (Donut Chart)
        sent_counts = df["æƒ…æ„Ÿåˆ†ç±»"].value_counts().reset_index()
        sent_counts.columns = ["æƒ…æ„Ÿ", "æ•°é‡"]
        fig_donut = px.pie(sent_counts, values="æ•°é‡", names="æƒ…æ„Ÿ", hole=0.4,
                           color="æƒ…æ„Ÿ",
                           color_discrete_map={"å¥½è¯„": "#2ecc71", "å·®è¯„": "#e74c3c"})
        st.plotly_chart(fig_donut, use_container_width=True)

    with col_chart2:
        st.subheader("æ ‡ç­¾å±‚çº§åˆ†å¸ƒ (æ—­æ—¥å›¾)")
        # æ—­æ—¥å›¾ (Sunburst)ï¼šå±•ç¤º æƒ…æ„Ÿ -> æ ‡ç­¾ çš„å±‚çº§
        # è¿‡æ»¤æ‰æ•°é‡å¤ªå°‘çš„æ ‡ç­¾ï¼Œé˜²æ­¢å›¾è¡¨å¤ªä¹±
        viz_df = df.copy()
        tag_counts = viz_df["æ ‡ç­¾"].value_counts()
        # æŠŠå‡ºç°å°‘äº2æ¬¡çš„æ ‡ç­¾å½’ä¸º"å…¶ä»–"
        viz_df["æ˜¾ç¤ºæ ‡ç­¾"] = viz_df["æ ‡ç­¾"].apply(lambda x: x if tag_counts[x] > 1 else "å…¶ä»–ä½é¢‘æ ‡ç­¾")
        
        count_df = viz_df.groupby(["æƒ…æ„Ÿåˆ†ç±»", "æ˜¾ç¤ºæ ‡ç­¾"]).size().reset_index(name="æ•°é‡")
        fig_sun = px.sunburst(count_df, path=['æƒ…æ„Ÿåˆ†ç±»', 'æ˜¾ç¤ºæ ‡ç­¾'], values='æ•°é‡',
                              color='æƒ…æ„Ÿåˆ†ç±»',
                              color_discrete_map={"å¥½è¯„": "#2ecc71", "å·®è¯„": "#e74c3c"})
        st.plotly_chart(fig_sun, use_container_width=True)

    # =========================
    # å¯è§†åŒ–æ¨¡å— C: è¯¦ç»†æ’è¡Œ
    # =========================
    st.markdown("---")
    st.subheader("ğŸ† çƒ­é—¨æ ‡ç­¾æ’è¡Œ (Top Issues)")
    
    # åŒºåˆ†é¢œè‰²ï¼šæ ‡å‡†åº“ vs æ–°å‘ç°
    std_set = set(POS_LABELS + NEG_LABELS)
    
    top_tags = df["æ ‡ç­¾"].value_counts().head(15).reset_index()
    top_tags.columns = ["æ ‡ç­¾å", "æåŠæ¬¡æ•°"]
    top_tags["ç±»å‹"] = top_tags["æ ‡ç­¾å"].apply(lambda x: "æ ‡å‡†åº“" if x in std_set else "æ–°å‘ç°")
    
    fig_bar = px.bar(top_tags, x="æåŠæ¬¡æ•°", y="æ ‡ç­¾å", orientation='h', 
                     color="ç±»å‹",
                     text="æåŠæ¬¡æ•°",
                     color_discrete_map={"æ ‡å‡†åº“": "#3498db", "æ–°å‘ç°": "#f1c40f"})
    fig_bar.update_layout(yaxis={'categoryorder':'total ascending'})
    st.plotly_chart(fig_bar, use_container_width=True)

    # =========================
    # æ¨¡å— D: å·®è¯„åŸå£°é€è§†
    # =========================
    st.markdown("---")
    st.header("3. å·®è¯„åŸå£°é€è§†")
    st.caption("ç‚¹å‡»ä¸‹æ–¹é€‰æ‹©ä¸€ä¸ªé—®é¢˜ï¼ŒæŸ¥çœ‹ç”¨æˆ·å…·ä½“åœ¨è¯´ä»€ä¹ˆ")
    
    neg_df = df[df["æƒ…æ„Ÿåˆ†ç±»"] == "å·®è¯„"]
    
    if not neg_df.empty:
        neg_issues = neg_df["æ ‡ç­¾"].value_counts().index.tolist()
        selected_issue = st.selectbox("é€‰æ‹©å·®è¯„æ ‡ç­¾:", neg_issues)
        
        reviews = neg_df[neg_df["æ ‡ç­¾"] == selected_issue]["text"].head(5)
        
        st.markdown(f"**å…³äºã€{selected_issue}ã€‘çš„ç”¨æˆ·åŸå£°:**")
        for i, txt in enumerate(reviews):
            st.info(f"{i+1}. {txt}")
    else:
        st.success("æš‚æ— å·®è¯„æ•°æ®ï¼")

    # =========================
    # ä¸‹è½½
    # =========================
    st.markdown("---")
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Analysis')
    
    st.download_button(
        label="â¬‡ï¸ ä¸‹è½½ Excel åˆ†ææŠ¥å‘Š",
        data=buffer.getvalue(),
        file_name="analysis_report.xlsx",
        mime="application/vnd.ms-excel"
    )
